{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import EasyTokenTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of using EasyTokenTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set example text and instantiate tagger instance\n",
    "example_text = '''Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions. \n",
    "The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.'''\n",
    "tagger = EasyTokenTagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-14 07:05:33,824 loading file /home/ubuntu/.flair/models/en-ner-ontonotes-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "# Tag the string\n",
    "sentences = tagger.tag_text(text = example_text, model_name_or_path = \"ner-ontonotes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List string outputs of tags:\n",
      "\n",
      "Novetta <B-ORG> Solutions <E-ORG> is the best . Albert <B-PERSON> Einstein <E-PERSON> used to be employed at Novetta <B-ORG> Solutions <E-ORG> . The Wright <S-PERSON> brothers loved to visit the JBF <S-ORG> headquarters , and they would have a chat with Albert <S-PERSON> .\n"
     ]
    }
   ],
   "source": [
    "# See Results\n",
    "print(\"List string outputs of tags:\\n\")\n",
    "for sen in sentences:\n",
    "    print(sen.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List entities tagged:\n",
      "\n",
      "ORG-span [1,2]: \"Novetta Solutions\"\n",
      "PERSON-span [7,8]: \"Albert Einstein\"\n",
      "ORG-span [14,15]: \"Novetta Solutions\"\n",
      "PERSON-span [18]: \"Wright\"\n",
      "ORG-span [24]: \"JBF\"\n",
      "PERSON-span [34]: \"Albert\"\n"
     ]
    }
   ],
   "source": [
    "print(\"List entities tagged:\\n\")\n",
    "for sen in sentences:\n",
    "    for entity in sen.get_spans(\"ner\"):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get json of tagged information:\n",
      "\n",
      "{'text': 'Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions.  The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.', 'labels': [], 'entities': [{'text': 'Novetta Solutions', 'start_pos': 0, 'end_pos': 17, 'type': 'ORG', 'confidence': 0.9644385576248169}, {'text': 'Albert Einstein', 'start_pos': 31, 'end_pos': 46, 'type': 'PERSON', 'confidence': 0.9968637228012085}, {'text': 'Novetta Solutions', 'start_pos': 70, 'end_pos': 87, 'type': 'ORG', 'confidence': 0.9795641601085663}, {'text': 'Wright', 'start_pos': 94, 'end_pos': 100, 'type': 'PERSON', 'confidence': 0.9994567036628723}, {'text': 'JBF', 'start_pos': 129, 'end_pos': 132, 'type': 'ORG', 'confidence': 0.9897594451904297}, {'text': 'Albert', 'start_pos': 179, 'end_pos': 185, 'type': 'PERSON', 'confidence': 0.9998805522918701}]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Get json of tagged information:\\n\")\n",
    "for sen in sentences:\n",
    "    print(sen.to_dict(tag_type=\"ner\"),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-14 07:05:42,907 loading file /home/ubuntu/.flair/models/en-pos-ontonotes-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "sentences = tagger.tag_text(text = example_text, model_name_or_path = \"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List string outputs of tags:\n",
      "\n",
      "Novetta <PROPN> Solutions <PROPN> is <VERB> the <DET> best <ADJ> . <PUNCT> Albert <PROPN> Einstein <PROPN> used <VERB> to <PART> be <VERB> employed <VERB> at <ADP> Novetta <PROPN> Solutions <PROPN> . <PUNCT> The <DET> Wright <PROPN> brothers <NOUN> loved <VERB> to <PART> visit <VERB> the <DET> JBF <PROPN> headquarters <NOUN> , <PUNCT> and <CCONJ> they <PRON> would <AUX> have <VERB> a <DET> chat <NOUN> with <ADP> Albert <PROPN> . <PUNCT>\n"
     ]
    }
   ],
   "source": [
    "# See Results\n",
    "print(\"List string outputs of tags:\\n\")\n",
    "for sen in sentences:\n",
    "    print(sen.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List text/entities tagged:\n",
      "\n",
      "PROPN-span [1]: \"Novetta\"\n",
      "PROPN-span [2]: \"Solutions\"\n",
      "VERB-span [3]: \"is\"\n",
      "DET-span [4]: \"the\"\n",
      "ADJ-span [5]: \"best\"\n",
      "PUNCT-span [6]: \".\"\n",
      "PROPN-span [7]: \"Albert\"\n",
      "PROPN-span [8]: \"Einstein\"\n",
      "VERB-span [9]: \"used\"\n",
      "PART-span [10]: \"to\"\n",
      "VERB-span [11]: \"be\"\n",
      "VERB-span [12]: \"employed\"\n",
      "ADP-span [13]: \"at\"\n",
      "PROPN-span [14]: \"Novetta\"\n",
      "PROPN-span [15]: \"Solutions\"\n",
      "PUNCT-span [16]: \".\"\n",
      "DET-span [17]: \"The\"\n",
      "PROPN-span [18]: \"Wright\"\n",
      "NOUN-span [19]: \"brothers\"\n",
      "VERB-span [20]: \"loved\"\n",
      "PART-span [21]: \"to\"\n",
      "VERB-span [22]: \"visit\"\n",
      "DET-span [23]: \"the\"\n",
      "PROPN-span [24]: \"JBF\"\n",
      "NOUN-span [25]: \"headquarters\"\n",
      "PUNCT-span [26]: \",\"\n",
      "CCONJ-span [27]: \"and\"\n",
      "PRON-span [28]: \"they\"\n",
      "AUX-span [29]: \"would\"\n",
      "VERB-span [30]: \"have\"\n",
      "DET-span [31]: \"a\"\n",
      "NOUN-span [32]: \"chat\"\n",
      "ADP-span [33]: \"with\"\n",
      "PROPN-span [34]: \"Albert\"\n",
      "PUNCT-span [35]: \".\"\n"
     ]
    }
   ],
   "source": [
    "print(\"List text/entities tagged:\\n\")\n",
    "for sen in sentences:\n",
    "    for entity in sen.get_spans(\"pos\"):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get json of tagged information:\n",
      "\n",
      "{'text': 'Novetta Solutions is the best. Albert Einstein used to be employed at Novetta Solutions.  The Wright brothers loved to visit the JBF headquarters, and they would have a chat with Albert.', 'labels': [], 'entities': [{'text': 'Novetta', 'start_pos': 0, 'end_pos': 7, 'type': 'PROPN', 'confidence': 0.996782660484314}, {'text': 'Solutions', 'start_pos': 8, 'end_pos': 17, 'type': 'PROPN', 'confidence': 0.9987585544586182}, {'text': 'is', 'start_pos': 18, 'end_pos': 20, 'type': 'VERB', 'confidence': 0.9999998807907104}, {'text': 'the', 'start_pos': 21, 'end_pos': 24, 'type': 'DET', 'confidence': 0.999997615814209}, {'text': 'best', 'start_pos': 25, 'end_pos': 29, 'type': 'ADJ', 'confidence': 0.988896906375885}, {'text': '.', 'start_pos': 29, 'end_pos': 30, 'type': 'PUNCT', 'confidence': 0.9999998807907104}, {'text': 'Albert', 'start_pos': 31, 'end_pos': 37, 'type': 'PROPN', 'confidence': 0.9998212456703186}, {'text': 'Einstein', 'start_pos': 38, 'end_pos': 46, 'type': 'PROPN', 'confidence': 0.9999752044677734}, {'text': 'used', 'start_pos': 47, 'end_pos': 51, 'type': 'VERB', 'confidence': 0.9999964237213135}, {'text': 'to', 'start_pos': 52, 'end_pos': 54, 'type': 'PART', 'confidence': 0.8238793611526489}, {'text': 'be', 'start_pos': 55, 'end_pos': 57, 'type': 'VERB', 'confidence': 1.0}, {'text': 'employed', 'start_pos': 58, 'end_pos': 66, 'type': 'VERB', 'confidence': 0.9814060926437378}, {'text': 'at', 'start_pos': 67, 'end_pos': 69, 'type': 'ADP', 'confidence': 0.9999970197677612}, {'text': 'Novetta', 'start_pos': 70, 'end_pos': 77, 'type': 'PROPN', 'confidence': 0.9996932744979858}, {'text': 'Solutions', 'start_pos': 78, 'end_pos': 87, 'type': 'PROPN', 'confidence': 0.9999144077301025}, {'text': '.', 'start_pos': 87, 'end_pos': 88, 'type': 'PUNCT', 'confidence': 0.9999995231628418}, {'text': 'The', 'start_pos': 90, 'end_pos': 93, 'type': 'DET', 'confidence': 0.9999369382858276}, {'text': 'Wright', 'start_pos': 94, 'end_pos': 100, 'type': 'PROPN', 'confidence': 0.9765077829360962}, {'text': 'brothers', 'start_pos': 101, 'end_pos': 109, 'type': 'NOUN', 'confidence': 0.9997797608375549}, {'text': 'loved', 'start_pos': 110, 'end_pos': 115, 'type': 'VERB', 'confidence': 0.9998679161071777}, {'text': 'to', 'start_pos': 116, 'end_pos': 118, 'type': 'PART', 'confidence': 0.9329371452331543}, {'text': 'visit', 'start_pos': 119, 'end_pos': 124, 'type': 'VERB', 'confidence': 0.9999938011169434}, {'text': 'the', 'start_pos': 125, 'end_pos': 128, 'type': 'DET', 'confidence': 0.9999831914901733}, {'text': 'JBF', 'start_pos': 129, 'end_pos': 132, 'type': 'PROPN', 'confidence': 0.9991439580917358}, {'text': 'headquarters', 'start_pos': 133, 'end_pos': 145, 'type': 'NOUN', 'confidence': 0.999893307685852}, {'text': ',', 'start_pos': 145, 'end_pos': 146, 'type': 'PUNCT', 'confidence': 1.0}, {'text': 'and', 'start_pos': 147, 'end_pos': 150, 'type': 'CCONJ', 'confidence': 0.9999997615814209}, {'text': 'they', 'start_pos': 151, 'end_pos': 155, 'type': 'PRON', 'confidence': 0.9999973773956299}, {'text': 'would', 'start_pos': 156, 'end_pos': 161, 'type': 'AUX', 'confidence': 0.9999995231628418}, {'text': 'have', 'start_pos': 162, 'end_pos': 166, 'type': 'VERB', 'confidence': 0.9999977350234985}, {'text': 'a', 'start_pos': 167, 'end_pos': 168, 'type': 'DET', 'confidence': 0.9998655319213867}, {'text': 'chat', 'start_pos': 169, 'end_pos': 173, 'type': 'NOUN', 'confidence': 0.9950767159461975}, {'text': 'with', 'start_pos': 174, 'end_pos': 178, 'type': 'ADP', 'confidence': 0.9999943971633911}, {'text': 'Albert', 'start_pos': 179, 'end_pos': 185, 'type': 'PROPN', 'confidence': 0.9998577833175659}, {'text': '.', 'start_pos': 185, 'end_pos': 186, 'type': 'PUNCT', 'confidence': 0.9999998807907104}]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Get json of tagged information:\\n\")\n",
    "for sen in sentences:\n",
    "    print(sen.to_dict(tag_type=\"pos\"),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-14 07:05:44,730 loading file /home/ubuntu/.flair/models/en-chunk-conll2000-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "sentences = tagger.tag_text(text = example_text, model_name_or_path = \"chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List string outputs of tags:\n",
      "\n",
      "Novetta <B-NP> Solutions <E-NP> is <S-VP> the <B-NP> best <E-NP> . Albert <B-NP> Einstein <E-NP> used <B-VP> to <I-VP> be <I-VP> employed <E-VP> at <S-PP> Novetta <B-NP> Solutions <E-NP> . The <B-NP> Wright <I-NP> brothers <E-NP> loved <B-VP> to <I-VP> visit <E-VP> the <B-NP> JBF <I-NP> headquarters <E-NP> , and they <S-NP> would <B-VP> have <E-VP> a <B-NP> chat <E-NP> with <S-PP> Albert <S-NP> .\n"
     ]
    }
   ],
   "source": [
    "# See Results\n",
    "print(\"List string outputs of tags:\\n\")\n",
    "for sen in sentences:\n",
    "    print(sen.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List text/entities tagged:\n",
      "\n",
      "NP-span [1,2]: \"Novetta Solutions\"\n",
      "VP-span [3]: \"is\"\n",
      "NP-span [4,5]: \"the best\"\n",
      "NP-span [7,8]: \"Albert Einstein\"\n",
      "VP-span [9,10,11,12]: \"used to be employed\"\n",
      "PP-span [13]: \"at\"\n",
      "NP-span [14,15]: \"Novetta Solutions\"\n",
      "NP-span [17,18,19]: \"The Wright brothers\"\n",
      "VP-span [20,21,22]: \"loved to visit\"\n",
      "NP-span [23,24,25]: \"the JBF headquarters\"\n",
      "NP-span [28]: \"they\"\n",
      "VP-span [29,30]: \"would have\"\n",
      "NP-span [31,32]: \"a chat\"\n",
      "PP-span [33]: \"with\"\n",
      "NP-span [34]: \"Albert\"\n"
     ]
    }
   ],
   "source": [
    "print(\"List text/entities tagged:\\n\")\n",
    "for sen in sentences:\n",
    "    for entity in sen.get_spans(\"np\"):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-14 07:05:45,281 loading file /home/ubuntu/.flair/models/en-frame-ontonotes-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "sentences = tagger.tag_text(text = example_text, model_name_or_path = \"frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List string outputs of tags:\n",
      "\n",
      "Novetta <_> Solutions <_> is <be.01> the <_> best <_> . <_> Albert <_> Einstein <_> used <use.03> to <_> be <be.03> employed <employ.01> at <_> Novetta <_> Solutions <_> . <_> The <_> Wright <_> brothers <_> loved <love.02> to <_> visit <visit.01> the <_> JBF <_> headquarters <_> , <_> and <_> they <_> would <_> have <have.03> a <_> chat <chat.01> with <_> Albert <_> . <_>\n"
     ]
    }
   ],
   "source": [
    "# See Results\n",
    "print(\"List string outputs of tags:\\n\")\n",
    "for sen in sentences:\n",
    "    print(sen.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Sequence Labeling\n",
    "#### Make sure to check out some of Flair's \"fast\" cpu-minded models that produce similar results to SOTA models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-14 07:05:46,098 loading file /home/ubuntu/.flair/models/en-ner-ontonotes-fast-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "# Tag the string\n",
    "sentences = tagger.tag_text(text = example_text, model_name_or_path = \"ner-ontonotes-fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List entities tagged:\n",
      "\n",
      "ORG-span [1,2]: \"Novetta Solutions\"\n",
      "PERSON-span [7,8]: \"Albert Einstein\"\n",
      "ORG-span [14,15]: \"Novetta Solutions\"\n",
      "PERSON-span [18]: \"Wright\"\n",
      "ORG-span [24]: \"JBF\"\n",
      "PERSON-span [34]: \"Albert\"\n"
     ]
    }
   ],
   "source": [
    "print(\"List entities tagged:\\n\")\n",
    "for sen in sentences:\n",
    "    for entity in sen.get_spans(\"ner\"):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Tokens with All Loaded Models At Once\n",
    "\n",
    "#### The tagger now has multiple models loaded after tagging all of the previous text\n",
    "#### This means with one method call of `tag_all(text)`, we can tag the text with all the loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tagger.tag_all(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List entities tagged:\n",
      "\n",
      "ORG-span [1,2]: \"Novetta Solutions\"\n",
      "PERSON-span [7,8]: \"Albert Einstein\"\n",
      "ORG-span [14,15]: \"Novetta Solutions\"\n",
      "PERSON-span [18]: \"Wright\"\n",
      "ORG-span [24]: \"JBF\"\n",
      "PERSON-span [34]: \"Albert\"\n"
     ]
    }
   ],
   "source": [
    "print(\"List entities tagged:\\n\")\n",
    "for sen in sentences:\n",
    "    for entity in sen.get_spans(\"ner\"):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List entities tagged:\n",
      "\n",
      "PROPN-span [1]: \"Novetta\"\n",
      "PROPN-span [2]: \"Solutions\"\n",
      "VERB-span [3]: \"is\"\n",
      "DET-span [4]: \"the\"\n",
      "ADJ-span [5]: \"best\"\n",
      "PUNCT-span [6]: \".\"\n",
      "PROPN-span [7]: \"Albert\"\n",
      "PROPN-span [8]: \"Einstein\"\n",
      "VERB-span [9]: \"used\"\n",
      "PART-span [10]: \"to\"\n",
      "VERB-span [11]: \"be\"\n",
      "VERB-span [12]: \"employed\"\n",
      "ADP-span [13]: \"at\"\n",
      "PROPN-span [14]: \"Novetta\"\n",
      "PROPN-span [15]: \"Solutions\"\n",
      "PUNCT-span [16]: \".\"\n",
      "DET-span [17]: \"The\"\n",
      "PROPN-span [18]: \"Wright\"\n",
      "NOUN-span [19]: \"brothers\"\n",
      "VERB-span [20]: \"loved\"\n",
      "PART-span [21]: \"to\"\n",
      "VERB-span [22]: \"visit\"\n",
      "DET-span [23]: \"the\"\n",
      "PROPN-span [24]: \"JBF\"\n",
      "NOUN-span [25]: \"headquarters\"\n",
      "PUNCT-span [26]: \",\"\n",
      "CCONJ-span [27]: \"and\"\n",
      "PRON-span [28]: \"they\"\n",
      "AUX-span [29]: \"would\"\n",
      "VERB-span [30]: \"have\"\n",
      "DET-span [31]: \"a\"\n",
      "NOUN-span [32]: \"chat\"\n",
      "ADP-span [33]: \"with\"\n",
      "PROPN-span [34]: \"Albert\"\n",
      "PUNCT-span [35]: \".\"\n"
     ]
    }
   ],
   "source": [
    "print(\"List entities tagged:\\n\")\n",
    "for sen in sentences:\n",
    "    for entity in sen.get_spans(\"pos\"):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List entities tagged:\n",
      "\n",
      "NP-span [1,2]: \"Novetta Solutions\"\n",
      "VP-span [3]: \"is\"\n",
      "NP-span [4,5]: \"the best\"\n",
      "NP-span [7,8]: \"Albert Einstein\"\n",
      "VP-span [9,10,11,12]: \"used to be employed\"\n",
      "PP-span [13]: \"at\"\n",
      "NP-span [14,15]: \"Novetta Solutions\"\n",
      "NP-span [17,18,19]: \"The Wright brothers\"\n",
      "VP-span [20,21,22]: \"loved to visit\"\n",
      "NP-span [23,24,25]: \"the JBF headquarters\"\n",
      "NP-span [28]: \"they\"\n",
      "VP-span [29,30]: \"would have\"\n",
      "NP-span [31,32]: \"a chat\"\n",
      "PP-span [33]: \"with\"\n",
      "NP-span [34]: \"Albert\"\n"
     ]
    }
   ],
   "source": [
    "print(\"List entities tagged:\\n\")\n",
    "for sen in sentences:\n",
    "    for entity in sen.get_spans(\"np\"):\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
