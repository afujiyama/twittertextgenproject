{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sequence Classifier Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptnlp import EasyDocumentEmbeddings, SequenceClassifierTrainer\n",
    "from flair.datasets import TREC_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize corpus, output directory for the model, and document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-17 06:32:27,268 Reading data from /home/andrew/.flair/datasets/trec_6\n",
      "2020-04-17 06:32:27,269 Train: /home/andrew/.flair/datasets/trec_6/train.txt\n",
      "2020-04-17 06:32:27,269 Dev: None\n",
      "2020-04-17 06:32:27,269 Test: /home/andrew/.flair/datasets/trec_6/test.txt\n",
      "May need a couple moments to instantiate...\n",
      "RNN embeddings loaded\n"
     ]
    }
   ],
   "source": [
    "corpus = TREC_6() # Or path to directory of train.csv, test.csv, dev.csv files at \"Path/to/data/directory\" \n",
    "OUTPUT_DIR = \"Path/to/model/output/directory\" \n",
    "doc_embeddings = EasyDocumentEmbeddings(\"bert-base-cased\", methods = [\"rnn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize Sequence Classification Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-17 06:32:30,279 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4907/4907 [00:00<00:00, 345482.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-17 06:32:30,295 [b'ENTY', b'HUM', b'DESC', b'LOC', b'NUM', b'ABBR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sc_configs = {\n",
    "              \"corpus\": corpus,\n",
    "              \"encoder\": doc_embeddings,\n",
    "              \"column_name_map\": {0: \"text\", 1: \"label\"},\n",
    "              \"corpus_in_memory\": True,\n",
    "              \"predictive_head\": \"flair\",\n",
    "             }\n",
    "sc_trainer = SequenceClassifierTrainer(**sc_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find Learning Rate with automated LR finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5135612484362082e-08]\n",
      "[1.8620871366628676e-08]\n",
      "[2.2908676527677733e-08]\n",
      "[2.818382931264454e-08]\n",
      "[3.4673685045253164e-08]\n",
      "[4.265795188015927e-08]\n",
      "[5.2480746024977265e-08]\n",
      "[6.456542290346554e-08]\n",
      "[7.943282347242815e-08]\n",
      "[9.772372209558107e-08]\n",
      "[1.2022644346174127e-07]\n",
      "[1.4791083881682077e-07]\n",
      "[1.819700858609984e-07]\n",
      "[2.2387211385683393e-07]\n",
      "[2.754228703338167e-07]\n",
      "[3.3884415613920264e-07]\n",
      "[4.168693834703353e-07]\n",
      "[5.128613839913649e-07]\n",
      "[6.309573444801935e-07]\n",
      "[7.762471166286916e-07]\n",
      "[9.54992586021436e-07]\n",
      "[1.1748975549395298e-06]\n",
      "[1.4454397707459273e-06]\n",
      "[1.778279410038923e-06]\n",
      "[2.187761623949553e-06]\n",
      "[2.6915348039269168e-06]\n",
      "[3.311311214825913e-06]\n",
      "[4.0738027780411255e-06]\n",
      "[5.011872336272722e-06]\n",
      "[6.165950018614822e-06]\n",
      "[7.585775750291839e-06]\n",
      "[9.332543007969913e-06]\n",
      "[1.1481536214968832e-05]\n",
      "[1.4125375446227536e-05]\n",
      "[1.737800828749375e-05]\n",
      "[2.1379620895022316e-05]\n",
      "[2.6302679918953824e-05]\n",
      "[3.2359365692962836e-05]\n",
      "[3.981071705534974e-05]\n",
      "[4.8977881936844595e-05]\n",
      "[6.025595860743576e-05]\n",
      "[7.413102413009174e-05]\n",
      "[9.120108393559098e-05]\n",
      "[0.00011220184543019637]\n",
      "[0.00013803842646028855]\n",
      "[0.00016982436524617435]\n",
      "[0.00020892961308540387]\n",
      "[0.00025703957827688637]\n",
      "[0.00031622776601683794]\n",
      "[0.0003890451449942807]\n",
      "[0.00047863009232263854]\n",
      "[0.0005888436553555893]\n",
      "[0.0007244359600749906]\n",
      "[0.0008912509381337464]\n",
      "[0.0010964781961431862]\n",
      "[0.001348962882591652]\n",
      "[0.0016595869074375593]\n",
      "[0.002041737944669528]\n",
      "[0.002511886431509579]\n",
      "[0.00309029543251359]\n",
      "[0.003801893963205612]\n",
      "[0.004677351412871982]\n",
      "[0.005754399373371571]\n",
      "[0.007079457843841382]\n",
      "[0.008709635899560813]\n",
      "[0.010715193052376074]\n",
      "[0.013182567385564083]\n",
      "[0.016218100973589285]\n",
      "[0.019952623149688778]\n",
      "[0.024547089156850287]\n",
      "[0.030199517204020147]\n",
      "[0.03715352290971724]\n",
      "[0.0457088189614875]\n",
      "[0.05623413251903491]\n",
      "[0.06918309709189367]\n",
      "[0.08511380382023769]\n",
      "[0.10471285480509002]\n",
      "[0.1288249551693135]\n",
      "[0.1584893192461115]\n",
      "[0.19498445997580477]\n",
      "[0.2398832919019488]\n",
      "[0.29512092266663836]\n",
      "[0.3630780547701011]\n",
      "[0.446683592150963]\n",
      "[0.5495408738576244]\n",
      "[0.6760829753919818]\n",
      "[0.8317637711026711]\n",
      "[1.0232929922807545]\n",
      "2020-04-17 06:32:35,818 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:35,818 loss diverged - stopping early!\n",
      "2020-04-17 06:32:35,827 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:35,828 learning rate finder finished - plot Path/to/model/output/directory/learning_rate.tsv\n",
      "2020-04-17 06:32:35,828 ----------------------------------------------------------------------------------------------------\n",
      "Learning_rate plots are saved in Path/to/model/output/directory/learning_rate.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Learning Rate 0.010715193052376074\n"
     ]
    }
   ],
   "source": [
    "sc_lr_configs = {\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \"file_name\": \"learning_rate.tsv\",\n",
    "        \"start_learning_rate\": 1e-8,\n",
    "        \"end_learning_rate\": 10,\n",
    "        \"iterations\": 100,\n",
    "        \"mini_batch_size\": 32,\n",
    "        \"lr_diff\": 16,\n",
    "        \"stop_early\": True,\n",
    "        \"smoothing_factor\": 0.8,\n",
    "        \"plot_learning_rate\": True,\n",
    "}\n",
    "learning_rate = sc_trainer.find_learning_rate(**sc_lr_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Sequence Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-17 06:32:36,404 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:36,405 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): BertEmbeddings(\n",
      "        (model): BertModel(\n",
      "          (embeddings): BertEmbeddings(\n",
      "            (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (token_type_embeddings): Embedding(2, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): BertEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): BertPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=3072, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=6, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-04-17 06:32:36,406 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:36,406 Corpus: \"Corpus: 4907 train + 545 dev + 500 test sentences\"\n",
      "2020-04-17 06:32:36,407 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:36,407 Parameters:\n",
      "2020-04-17 06:32:36,407  - learning_rate: \"0.010715193052376074\"\n",
      "2020-04-17 06:32:36,408  - mini_batch_size: \"32\"\n",
      "2020-04-17 06:32:36,408  - patience: \"5\"\n",
      "2020-04-17 06:32:36,408  - anneal_factor: \"0.5\"\n",
      "2020-04-17 06:32:36,408  - max_epochs: \"150\"\n",
      "2020-04-17 06:32:36,409  - shuffle: \"True\"\n",
      "2020-04-17 06:32:36,409  - train_with_dev: \"False\"\n",
      "2020-04-17 06:32:36,409  - batch_growth_annealing: \"False\"\n",
      "2020-04-17 06:32:36,409 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:36,410 Model training base path: \"Path/to/model/output/directory\"\n",
      "2020-04-17 06:32:36,410 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:36,410 Device: cuda:0\n",
      "2020-04-17 06:32:36,411 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:36,411 Embeddings storage mode: cpu\n",
      "2020-04-17 06:32:36,418 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:37,410 epoch 1 - iter 15/154 - loss 2.14709326 - samples/sec: 485.18\n",
      "2020-04-17 06:32:38,404 epoch 1 - iter 30/154 - loss 2.10631451 - samples/sec: 534.71\n",
      "2020-04-17 06:32:39,420 epoch 1 - iter 45/154 - loss 2.09580517 - samples/sec: 516.19\n",
      "2020-04-17 06:32:40,454 epoch 1 - iter 60/154 - loss 2.06484732 - samples/sec: 506.09\n",
      "2020-04-17 06:32:41,494 epoch 1 - iter 75/154 - loss 2.04995669 - samples/sec: 503.35\n",
      "2020-04-17 06:32:42,489 epoch 1 - iter 90/154 - loss 2.03238160 - samples/sec: 528.37\n",
      "2020-04-17 06:32:43,490 epoch 1 - iter 105/154 - loss 2.01493842 - samples/sec: 524.30\n",
      "2020-04-17 06:32:44,510 epoch 1 - iter 120/154 - loss 2.00262879 - samples/sec: 513.33\n",
      "2020-04-17 06:32:45,525 epoch 1 - iter 135/154 - loss 1.99438971 - samples/sec: 518.16\n",
      "2020-04-17 06:32:46,552 epoch 1 - iter 150/154 - loss 1.98078825 - samples/sec: 511.31\n",
      "2020-04-17 06:32:46,851 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:46,851 EPOCH 1 done: loss 1.9755 - lr 0.0107\n",
      "2020-04-17 06:32:47,864 DEV : loss 1.572764277458191 - score 0.3266\n",
      "2020-04-17 06:32:47,872 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:32:48,410 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:48,652 epoch 2 - iter 15/154 - loss 1.87482791 - samples/sec: 2009.35\n",
      "2020-04-17 06:32:48,947 epoch 2 - iter 30/154 - loss 1.82124199 - samples/sec: 2284.84\n",
      "2020-04-17 06:32:49,237 epoch 2 - iter 45/154 - loss 1.80459935 - samples/sec: 2336.24\n",
      "2020-04-17 06:32:49,524 epoch 2 - iter 60/154 - loss 1.79215007 - samples/sec: 2377.64\n",
      "2020-04-17 06:32:49,823 epoch 2 - iter 75/154 - loss 1.78026255 - samples/sec: 2236.87\n",
      "2020-04-17 06:32:50,126 epoch 2 - iter 90/154 - loss 1.76946618 - samples/sec: 2200.94\n",
      "2020-04-17 06:32:50,416 epoch 2 - iter 105/154 - loss 1.75171069 - samples/sec: 2348.84\n",
      "2020-04-17 06:32:50,720 epoch 2 - iter 120/154 - loss 1.75352812 - samples/sec: 2188.48\n",
      "2020-04-17 06:32:51,022 epoch 2 - iter 135/154 - loss 1.74217262 - samples/sec: 2213.06\n",
      "2020-04-17 06:32:51,333 epoch 2 - iter 150/154 - loss 1.73004287 - samples/sec: 2125.25\n",
      "2020-04-17 06:32:51,486 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:51,486 EPOCH 2 done: loss 1.7294 - lr 0.0107\n",
      "2020-04-17 06:32:51,693 DEV : loss 1.558794379234314 - score 0.3761\n",
      "2020-04-17 06:32:51,700 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:32:52,238 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:52,488 epoch 3 - iter 15/154 - loss 1.65929530 - samples/sec: 1937.33\n",
      "2020-04-17 06:32:52,790 epoch 3 - iter 30/154 - loss 1.65063629 - samples/sec: 2212.08\n",
      "2020-04-17 06:32:53,090 epoch 3 - iter 45/154 - loss 1.64321502 - samples/sec: 2217.69\n",
      "2020-04-17 06:32:53,389 epoch 3 - iter 60/154 - loss 1.60638597 - samples/sec: 2250.30\n",
      "2020-04-17 06:32:53,696 epoch 3 - iter 75/154 - loss 1.58826162 - samples/sec: 2162.67\n",
      "2020-04-17 06:32:53,990 epoch 3 - iter 90/154 - loss 1.58279863 - samples/sec: 2281.99\n",
      "2020-04-17 06:32:54,292 epoch 3 - iter 105/154 - loss 1.57161422 - samples/sec: 2211.02\n",
      "2020-04-17 06:32:54,591 epoch 3 - iter 120/154 - loss 1.54747841 - samples/sec: 2229.10\n",
      "2020-04-17 06:32:54,895 epoch 3 - iter 135/154 - loss 1.53266510 - samples/sec: 2187.18\n",
      "2020-04-17 06:32:55,201 epoch 3 - iter 150/154 - loss 1.52865915 - samples/sec: 2175.55\n",
      "2020-04-17 06:32:55,340 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:55,341 EPOCH 3 done: loss 1.5265 - lr 0.0107\n",
      "2020-04-17 06:32:55,542 DEV : loss 1.512552261352539 - score 0.3083\n",
      "2020-04-17 06:32:55,550 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:32:55,551 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:55,795 epoch 4 - iter 15/154 - loss 1.35226681 - samples/sec: 1983.97\n",
      "2020-04-17 06:32:56,094 epoch 4 - iter 30/154 - loss 1.37612681 - samples/sec: 2236.02\n",
      "2020-04-17 06:32:56,394 epoch 4 - iter 45/154 - loss 1.37836168 - samples/sec: 2236.19\n",
      "2020-04-17 06:32:56,702 epoch 4 - iter 60/154 - loss 1.36304837 - samples/sec: 2176.18\n",
      "2020-04-17 06:32:56,997 epoch 4 - iter 75/154 - loss 1.34951853 - samples/sec: 2310.87\n",
      "2020-04-17 06:32:57,308 epoch 4 - iter 90/154 - loss 1.35378158 - samples/sec: 2155.59\n",
      "2020-04-17 06:32:57,615 epoch 4 - iter 105/154 - loss 1.34148567 - samples/sec: 2210.22\n",
      "2020-04-17 06:32:57,923 epoch 4 - iter 120/154 - loss 1.33504071 - samples/sec: 2179.13\n",
      "2020-04-17 06:32:58,229 epoch 4 - iter 135/154 - loss 1.32736493 - samples/sec: 2208.68\n",
      "2020-04-17 06:32:58,545 epoch 4 - iter 150/154 - loss 1.32063609 - samples/sec: 2107.82\n",
      "2020-04-17 06:32:58,688 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:58,689 EPOCH 4 done: loss 1.3171 - lr 0.0107\n",
      "2020-04-17 06:32:58,886 DEV : loss 1.312379002571106 - score 0.5284\n",
      "2020-04-17 06:32:58,894 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:32:59,413 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:32:59,674 epoch 5 - iter 15/154 - loss 1.21441988 - samples/sec: 1864.53\n",
      "2020-04-17 06:32:59,982 epoch 5 - iter 30/154 - loss 1.22140887 - samples/sec: 2190.49\n",
      "2020-04-17 06:33:00,300 epoch 5 - iter 45/154 - loss 1.20418999 - samples/sec: 2118.30\n",
      "2020-04-17 06:33:00,607 epoch 5 - iter 60/154 - loss 1.19858224 - samples/sec: 2247.97\n",
      "2020-04-17 06:33:00,918 epoch 5 - iter 75/154 - loss 1.19776692 - samples/sec: 2207.24\n",
      "2020-04-17 06:33:01,219 epoch 5 - iter 90/154 - loss 1.18038319 - samples/sec: 2244.07\n",
      "2020-04-17 06:33:01,523 epoch 5 - iter 105/154 - loss 1.18407100 - samples/sec: 2218.43\n",
      "2020-04-17 06:33:01,841 epoch 5 - iter 120/154 - loss 1.17665039 - samples/sec: 2218.49\n",
      "2020-04-17 06:33:02,148 epoch 5 - iter 135/154 - loss 1.17614261 - samples/sec: 2173.25\n",
      "2020-04-17 06:33:02,444 epoch 5 - iter 150/154 - loss 1.17041967 - samples/sec: 2280.08\n",
      "2020-04-17 06:33:02,586 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:02,587 EPOCH 5 done: loss 1.1663 - lr 0.0107\n",
      "2020-04-17 06:33:02,775 DEV : loss 1.0993443727493286 - score 0.6312\n",
      "2020-04-17 06:33:02,783 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:33:03,315 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:03,558 epoch 6 - iter 15/154 - loss 1.10712562 - samples/sec: 1991.94\n",
      "2020-04-17 06:33:03,872 epoch 6 - iter 30/154 - loss 1.09175612 - samples/sec: 2168.30\n",
      "2020-04-17 06:33:04,187 epoch 6 - iter 45/154 - loss 1.08419862 - samples/sec: 2113.51\n",
      "2020-04-17 06:33:04,488 epoch 6 - iter 60/154 - loss 1.05868861 - samples/sec: 2274.10\n",
      "2020-04-17 06:33:04,793 epoch 6 - iter 75/154 - loss 1.05307886 - samples/sec: 2211.70\n",
      "2020-04-17 06:33:05,094 epoch 6 - iter 90/154 - loss 1.04651748 - samples/sec: 2247.95\n",
      "2020-04-17 06:33:05,394 epoch 6 - iter 105/154 - loss 1.03676561 - samples/sec: 2278.43\n",
      "2020-04-17 06:33:05,707 epoch 6 - iter 120/154 - loss 1.03000970 - samples/sec: 2154.19\n",
      "2020-04-17 06:33:06,014 epoch 6 - iter 135/154 - loss 1.02516786 - samples/sec: 2181.44\n",
      "2020-04-17 06:33:06,326 epoch 6 - iter 150/154 - loss 1.01668155 - samples/sec: 2143.57\n",
      "2020-04-17 06:33:06,467 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:06,468 EPOCH 6 done: loss 1.0149 - lr 0.0107\n",
      "2020-04-17 06:33:06,660 DEV : loss 1.056357979774475 - score 0.6624\n",
      "2020-04-17 06:33:06,668 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:33:07,180 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:07,430 epoch 7 - iter 15/154 - loss 1.02657772 - samples/sec: 1939.28\n",
      "2020-04-17 06:33:07,742 epoch 7 - iter 30/154 - loss 0.98921984 - samples/sec: 2136.04\n",
      "2020-04-17 06:33:08,055 epoch 7 - iter 45/154 - loss 0.98790514 - samples/sec: 2135.76\n",
      "2020-04-17 06:33:08,365 epoch 7 - iter 60/154 - loss 0.97213956 - samples/sec: 2179.62\n",
      "2020-04-17 06:33:08,676 epoch 7 - iter 75/154 - loss 0.95709557 - samples/sec: 2135.74\n",
      "2020-04-17 06:33:08,980 epoch 7 - iter 90/154 - loss 0.94414539 - samples/sec: 2212.41\n",
      "2020-04-17 06:33:09,294 epoch 7 - iter 105/154 - loss 0.94221938 - samples/sec: 2129.08\n",
      "2020-04-17 06:33:09,595 epoch 7 - iter 120/154 - loss 0.94269521 - samples/sec: 2250.26\n",
      "2020-04-17 06:33:09,901 epoch 7 - iter 135/154 - loss 0.93200419 - samples/sec: 2206.32\n",
      "2020-04-17 06:33:10,220 epoch 7 - iter 150/154 - loss 0.92447333 - samples/sec: 2069.10\n",
      "2020-04-17 06:33:10,369 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:10,370 EPOCH 7 done: loss 0.9236 - lr 0.0107\n",
      "2020-04-17 06:33:10,569 DEV : loss 0.8646987080574036 - score 0.6954\n",
      "2020-04-17 06:33:10,578 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:33:11,113 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:11,357 epoch 8 - iter 15/154 - loss 0.84706806 - samples/sec: 1990.65\n",
      "2020-04-17 06:33:11,661 epoch 8 - iter 30/154 - loss 0.83182167 - samples/sec: 2209.83\n",
      "2020-04-17 06:33:11,964 epoch 8 - iter 45/154 - loss 0.83512260 - samples/sec: 2206.39\n",
      "2020-04-17 06:33:12,267 epoch 8 - iter 60/154 - loss 0.84501980 - samples/sec: 2211.55\n",
      "2020-04-17 06:33:12,567 epoch 8 - iter 75/154 - loss 0.83595228 - samples/sec: 2233.87\n",
      "2020-04-17 06:33:12,866 epoch 8 - iter 90/154 - loss 0.84873171 - samples/sec: 2260.84\n",
      "2020-04-17 06:33:13,162 epoch 8 - iter 105/154 - loss 0.83996388 - samples/sec: 2263.61\n",
      "2020-04-17 06:33:13,457 epoch 8 - iter 120/154 - loss 0.83149581 - samples/sec: 2281.17\n",
      "2020-04-17 06:33:13,747 epoch 8 - iter 135/154 - loss 0.82434229 - samples/sec: 2341.46\n",
      "2020-04-17 06:33:14,044 epoch 8 - iter 150/154 - loss 0.82571336 - samples/sec: 2266.70\n",
      "2020-04-17 06:33:14,179 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:14,180 EPOCH 8 done: loss 0.8249 - lr 0.0107\n",
      "2020-04-17 06:33:14,377 DEV : loss 0.6730138659477234 - score 0.778\n",
      "2020-04-17 06:33:14,385 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:33:14,921 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:15,171 epoch 9 - iter 15/154 - loss 0.79223144 - samples/sec: 1949.03\n",
      "2020-04-17 06:33:15,459 epoch 9 - iter 30/154 - loss 0.76579743 - samples/sec: 2354.99\n",
      "2020-04-17 06:33:15,757 epoch 9 - iter 45/154 - loss 0.77132826 - samples/sec: 2253.54\n",
      "2020-04-17 06:33:16,052 epoch 9 - iter 60/154 - loss 0.76257378 - samples/sec: 2286.61\n",
      "2020-04-17 06:33:16,350 epoch 9 - iter 75/154 - loss 0.76039226 - samples/sec: 2266.00\n",
      "2020-04-17 06:33:16,655 epoch 9 - iter 90/154 - loss 0.75170724 - samples/sec: 2270.06\n",
      "2020-04-17 06:33:16,963 epoch 9 - iter 105/154 - loss 0.74796047 - samples/sec: 2318.76\n",
      "2020-04-17 06:33:17,260 epoch 9 - iter 120/154 - loss 0.74682364 - samples/sec: 2269.91\n",
      "2020-04-17 06:33:17,549 epoch 9 - iter 135/154 - loss 0.73507245 - samples/sec: 2345.22\n",
      "2020-04-17 06:33:17,847 epoch 9 - iter 150/154 - loss 0.72995527 - samples/sec: 2263.49\n",
      "2020-04-17 06:33:17,980 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:17,981 EPOCH 9 done: loss 0.7233 - lr 0.0107\n",
      "2020-04-17 06:33:18,185 DEV : loss 0.8491551876068115 - score 0.6532\n",
      "2020-04-17 06:33:18,194 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:33:18,194 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:18,413 epoch 10 - iter 15/154 - loss 0.69719307 - samples/sec: 2215.19\n",
      "2020-04-17 06:33:18,712 epoch 10 - iter 30/154 - loss 0.70785255 - samples/sec: 2229.26\n",
      "2020-04-17 06:33:19,010 epoch 10 - iter 45/154 - loss 0.68446374 - samples/sec: 2268.67\n",
      "2020-04-17 06:33:19,308 epoch 10 - iter 60/154 - loss 0.67841487 - samples/sec: 2241.03\n",
      "2020-04-17 06:33:19,605 epoch 10 - iter 75/154 - loss 0.67611039 - samples/sec: 2273.95\n",
      "2020-04-17 06:33:19,904 epoch 10 - iter 90/154 - loss 0.67147699 - samples/sec: 2305.83\n",
      "2020-04-17 06:33:20,209 epoch 10 - iter 105/154 - loss 0.67505563 - samples/sec: 2231.63\n",
      "2020-04-17 06:33:20,501 epoch 10 - iter 120/154 - loss 0.67425249 - samples/sec: 2342.02\n",
      "2020-04-17 06:33:20,800 epoch 10 - iter 135/154 - loss 0.67045458 - samples/sec: 2279.85\n",
      "2020-04-17 06:33:21,100 epoch 10 - iter 150/154 - loss 0.66607209 - samples/sec: 2259.35\n",
      "2020-04-17 06:33:21,246 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:21,246 EPOCH 10 done: loss 0.6650 - lr 0.0107\n",
      "2020-04-17 06:33:21,440 DEV : loss 0.5405022501945496 - score 0.7982\n",
      "2020-04-17 06:33:21,448 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:33:21,980 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:22,228 epoch 11 - iter 15/154 - loss 0.55996707 - samples/sec: 1963.64\n",
      "2020-04-17 06:33:22,524 epoch 11 - iter 30/154 - loss 0.56638068 - samples/sec: 2290.74\n",
      "2020-04-17 06:33:22,825 epoch 11 - iter 45/154 - loss 0.58904082 - samples/sec: 2242.04\n",
      "2020-04-17 06:33:23,130 epoch 11 - iter 60/154 - loss 0.59376199 - samples/sec: 2212.89\n",
      "2020-04-17 06:33:23,423 epoch 11 - iter 75/154 - loss 0.59135066 - samples/sec: 2344.40\n",
      "2020-04-17 06:33:23,726 epoch 11 - iter 90/154 - loss 0.58751693 - samples/sec: 2228.51\n",
      "2020-04-17 06:33:24,024 epoch 11 - iter 105/154 - loss 0.58383799 - samples/sec: 2294.32\n",
      "2020-04-17 06:33:24,332 epoch 11 - iter 120/154 - loss 0.58150161 - samples/sec: 2197.40\n",
      "2020-04-17 06:33:24,634 epoch 11 - iter 135/154 - loss 0.58403028 - samples/sec: 2240.94\n",
      "2020-04-17 06:33:24,936 epoch 11 - iter 150/154 - loss 0.58617010 - samples/sec: 2256.73\n",
      "2020-04-17 06:33:25,078 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:25,078 EPOCH 11 done: loss 0.5876 - lr 0.0107\n",
      "2020-04-17 06:33:25,265 DEV : loss 0.4189220070838928 - score 0.8569\n",
      "2020-04-17 06:33:25,273 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:33:25,907 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:26,161 epoch 12 - iter 15/154 - loss 0.53283249 - samples/sec: 1936.10\n",
      "2020-04-17 06:33:26,466 epoch 12 - iter 30/154 - loss 0.54786084 - samples/sec: 2215.61\n",
      "2020-04-17 06:33:26,773 epoch 12 - iter 45/154 - loss 0.55159223 - samples/sec: 2206.91\n",
      "2020-04-17 06:33:27,072 epoch 12 - iter 60/154 - loss 0.55386149 - samples/sec: 2291.37\n",
      "2020-04-17 06:33:27,376 epoch 12 - iter 75/154 - loss 0.54426650 - samples/sec: 2260.28\n",
      "2020-04-17 06:33:27,679 epoch 12 - iter 90/154 - loss 0.55137579 - samples/sec: 2213.90\n",
      "2020-04-17 06:33:27,995 epoch 12 - iter 105/154 - loss 0.55267709 - samples/sec: 2096.12\n",
      "2020-04-17 06:33:28,325 epoch 12 - iter 120/154 - loss 0.55061194 - samples/sec: 1993.75\n",
      "2020-04-17 06:33:28,726 epoch 12 - iter 135/154 - loss 0.54396141 - samples/sec: 1539.00\n",
      "2020-04-17 06:33:29,242 epoch 12 - iter 150/154 - loss 0.53952611 - samples/sec: 1119.87\n",
      "2020-04-17 06:33:29,387 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:29,387 EPOCH 12 done: loss 0.5416 - lr 0.0107\n",
      "2020-04-17 06:33:29,761 DEV : loss 0.45619896054267883 - score 0.8073\n",
      "2020-04-17 06:33:29,770 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:33:29,770 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:30,190 epoch 13 - iter 15/154 - loss 0.45928809 - samples/sec: 1148.20\n",
      "2020-04-17 06:33:30,498 epoch 13 - iter 30/154 - loss 0.50076957 - samples/sec: 2222.76\n",
      "2020-04-17 06:33:30,807 epoch 13 - iter 45/154 - loss 0.50356765 - samples/sec: 2224.25\n",
      "2020-04-17 06:33:31,107 epoch 13 - iter 60/154 - loss 0.49174725 - samples/sec: 2264.04\n",
      "2020-04-17 06:33:31,410 epoch 13 - iter 75/154 - loss 0.49628167 - samples/sec: 2226.29\n",
      "2020-04-17 06:33:31,717 epoch 13 - iter 90/154 - loss 0.48865115 - samples/sec: 2171.87\n",
      "2020-04-17 06:33:32,028 epoch 13 - iter 105/154 - loss 0.48938499 - samples/sec: 2275.33\n",
      "2020-04-17 06:33:32,324 epoch 13 - iter 120/154 - loss 0.49102722 - samples/sec: 2295.03\n",
      "2020-04-17 06:33:32,625 epoch 13 - iter 135/154 - loss 0.49708143 - samples/sec: 2227.83\n",
      "2020-04-17 06:33:32,925 epoch 13 - iter 150/154 - loss 0.49523887 - samples/sec: 2231.66\n",
      "2020-04-17 06:33:33,063 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:33,063 EPOCH 13 done: loss 0.4932 - lr 0.0107\n",
      "2020-04-17 06:33:33,262 DEV : loss 0.3918561637401581 - score 0.8642\n",
      "2020-04-17 06:33:33,270 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:33:33,811 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:34,073 epoch 14 - iter 15/154 - loss 0.48108093 - samples/sec: 1894.76\n",
      "2020-04-17 06:33:34,368 epoch 14 - iter 30/154 - loss 0.45642985 - samples/sec: 2324.27\n",
      "2020-04-17 06:33:34,667 epoch 14 - iter 45/154 - loss 0.48343533 - samples/sec: 2267.22\n",
      "2020-04-17 06:33:34,968 epoch 14 - iter 60/154 - loss 0.46342909 - samples/sec: 2293.36\n",
      "2020-04-17 06:33:35,273 epoch 14 - iter 75/154 - loss 0.46014433 - samples/sec: 2227.47\n",
      "2020-04-17 06:33:35,560 epoch 14 - iter 90/154 - loss 0.45276263 - samples/sec: 2394.73\n",
      "2020-04-17 06:33:35,857 epoch 14 - iter 105/154 - loss 0.44649029 - samples/sec: 2308.53\n",
      "2020-04-17 06:33:36,168 epoch 14 - iter 120/154 - loss 0.45039730 - samples/sec: 2167.24\n",
      "2020-04-17 06:33:36,475 epoch 14 - iter 135/154 - loss 0.45213617 - samples/sec: 2199.65\n",
      "2020-04-17 06:33:36,792 epoch 14 - iter 150/154 - loss 0.45238115 - samples/sec: 2096.67\n",
      "2020-04-17 06:33:36,946 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:36,947 EPOCH 14 done: loss 0.4523 - lr 0.0107\n",
      "2020-04-17 06:33:37,154 DEV : loss 0.3325881361961365 - score 0.8844\n",
      "2020-04-17 06:33:37,161 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:33:37,697 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:37,968 epoch 15 - iter 15/154 - loss 0.43153795 - samples/sec: 1804.05\n",
      "2020-04-17 06:33:38,282 epoch 15 - iter 30/154 - loss 0.44080856 - samples/sec: 2176.55\n",
      "2020-04-17 06:33:38,586 epoch 15 - iter 45/154 - loss 0.45121252 - samples/sec: 2250.09\n",
      "2020-04-17 06:33:38,898 epoch 15 - iter 60/154 - loss 0.44239275 - samples/sec: 2176.43\n",
      "2020-04-17 06:33:39,465 epoch 15 - iter 75/154 - loss 0.44924199 - samples/sec: 1009.64\n",
      "2020-04-17 06:33:39,784 epoch 15 - iter 90/154 - loss 0.45050204 - samples/sec: 2084.78\n",
      "2020-04-17 06:33:40,089 epoch 15 - iter 105/154 - loss 0.44704995 - samples/sec: 2216.98\n",
      "2020-04-17 06:33:40,400 epoch 15 - iter 120/154 - loss 0.44303660 - samples/sec: 2203.49\n",
      "2020-04-17 06:33:40,705 epoch 15 - iter 135/154 - loss 0.44178738 - samples/sec: 2204.89\n",
      "2020-04-17 06:33:41,002 epoch 15 - iter 150/154 - loss 0.43606687 - samples/sec: 2294.80\n",
      "2020-04-17 06:33:41,159 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:41,159 EPOCH 15 done: loss 0.4357 - lr 0.0107\n",
      "2020-04-17 06:33:41,482 DEV : loss 0.36468687653541565 - score 0.8606\n",
      "2020-04-17 06:33:41,491 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:33:41,491 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:41,884 epoch 16 - iter 15/154 - loss 0.37089783 - samples/sec: 1228.37\n",
      "2020-04-17 06:33:42,264 epoch 16 - iter 30/154 - loss 0.37512023 - samples/sec: 1725.96\n",
      "2020-04-17 06:33:42,611 epoch 16 - iter 45/154 - loss 0.38716085 - samples/sec: 1880.06\n",
      "2020-04-17 06:33:42,911 epoch 16 - iter 60/154 - loss 0.38476359 - samples/sec: 2234.06\n",
      "2020-04-17 06:33:43,243 epoch 16 - iter 75/154 - loss 0.39235766 - samples/sec: 1943.23\n",
      "2020-04-17 06:33:43,625 epoch 16 - iter 90/154 - loss 0.39098009 - samples/sec: 1645.19\n",
      "2020-04-17 06:33:44,017 epoch 16 - iter 105/154 - loss 0.40103606 - samples/sec: 1578.54\n",
      "2020-04-17 06:33:44,325 epoch 16 - iter 120/154 - loss 0.39764620 - samples/sec: 2168.39\n",
      "2020-04-17 06:33:44,639 epoch 16 - iter 135/154 - loss 0.39843063 - samples/sec: 2177.98\n",
      "2020-04-17 06:33:44,956 epoch 16 - iter 150/154 - loss 0.39913756 - samples/sec: 2166.23\n",
      "2020-04-17 06:33:45,106 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:45,106 EPOCH 16 done: loss 0.4019 - lr 0.0107\n",
      "2020-04-17 06:33:45,370 DEV : loss 0.3824766278266907 - score 0.8532\n",
      "2020-04-17 06:33:45,378 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:33:45,379 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:45,629 epoch 17 - iter 15/154 - loss 0.44469359 - samples/sec: 1933.88\n",
      "2020-04-17 06:33:45,930 epoch 17 - iter 30/154 - loss 0.42735072 - samples/sec: 2283.01\n",
      "2020-04-17 06:33:46,233 epoch 17 - iter 45/154 - loss 0.39859888 - samples/sec: 2242.70\n",
      "2020-04-17 06:33:46,544 epoch 17 - iter 60/154 - loss 0.40322910 - samples/sec: 2157.65\n",
      "2020-04-17 06:33:46,844 epoch 17 - iter 75/154 - loss 0.39632624 - samples/sec: 2282.24\n",
      "2020-04-17 06:33:47,169 epoch 17 - iter 90/154 - loss 0.38519371 - samples/sec: 2206.71\n",
      "2020-04-17 06:33:47,478 epoch 17 - iter 105/154 - loss 0.37459264 - samples/sec: 2258.73\n",
      "2020-04-17 06:33:47,786 epoch 17 - iter 120/154 - loss 0.38268849 - samples/sec: 2245.56\n",
      "2020-04-17 06:33:48,093 epoch 17 - iter 135/154 - loss 0.38287453 - samples/sec: 2232.47\n",
      "2020-04-17 06:33:48,403 epoch 17 - iter 150/154 - loss 0.38014972 - samples/sec: 2222.41\n",
      "2020-04-17 06:33:48,547 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:48,548 EPOCH 17 done: loss 0.3813 - lr 0.0107\n",
      "2020-04-17 06:33:48,728 DEV : loss 0.43606993556022644 - score 0.833\n",
      "2020-04-17 06:33:48,736 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:33:48,736 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:48,972 epoch 18 - iter 15/154 - loss 0.38806884 - samples/sec: 2053.68\n",
      "2020-04-17 06:33:49,271 epoch 18 - iter 30/154 - loss 0.41620345 - samples/sec: 2266.21\n",
      "2020-04-17 06:33:49,572 epoch 18 - iter 45/154 - loss 0.39190269 - samples/sec: 2255.83\n",
      "2020-04-17 06:33:49,867 epoch 18 - iter 60/154 - loss 0.37061037 - samples/sec: 2309.37\n",
      "2020-04-17 06:33:50,170 epoch 18 - iter 75/154 - loss 0.37461238 - samples/sec: 2225.39\n",
      "2020-04-17 06:33:50,468 epoch 18 - iter 90/154 - loss 0.37281205 - samples/sec: 2277.57\n",
      "2020-04-17 06:33:50,766 epoch 18 - iter 105/154 - loss 0.36589808 - samples/sec: 2279.02\n",
      "2020-04-17 06:33:51,061 epoch 18 - iter 120/154 - loss 0.36938611 - samples/sec: 2318.45\n",
      "2020-04-17 06:33:51,365 epoch 18 - iter 135/154 - loss 0.36725451 - samples/sec: 2215.69\n",
      "2020-04-17 06:33:51,663 epoch 18 - iter 150/154 - loss 0.36630660 - samples/sec: 2277.99\n",
      "2020-04-17 06:33:51,840 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:51,840 EPOCH 18 done: loss 0.3638 - lr 0.0107\n",
      "2020-04-17 06:33:52,123 DEV : loss 0.35368824005126953 - score 0.8661\n",
      "2020-04-17 06:33:52,131 BAD EPOCHS (no improvement): 4\n",
      "2020-04-17 06:33:52,138 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:52,354 epoch 19 - iter 15/154 - loss 0.37224739 - samples/sec: 2241.22\n",
      "2020-04-17 06:33:52,649 epoch 19 - iter 30/154 - loss 0.34465811 - samples/sec: 2306.16\n",
      "2020-04-17 06:33:52,986 epoch 19 - iter 45/154 - loss 0.35725955 - samples/sec: 1913.87\n",
      "2020-04-17 06:33:53,315 epoch 19 - iter 60/154 - loss 0.35033687 - samples/sec: 1996.03\n",
      "2020-04-17 06:33:53,628 epoch 19 - iter 75/154 - loss 0.35027044 - samples/sec: 2120.66\n",
      "2020-04-17 06:33:53,983 epoch 19 - iter 90/154 - loss 0.34294775 - samples/sec: 1810.40\n",
      "2020-04-17 06:33:54,300 epoch 19 - iter 105/154 - loss 0.34381433 - samples/sec: 2105.76\n",
      "2020-04-17 06:33:54,755 epoch 19 - iter 120/154 - loss 0.34311300 - samples/sec: 1316.84\n",
      "2020-04-17 06:33:55,182 epoch 19 - iter 135/154 - loss 0.34064811 - samples/sec: 1429.57\n",
      "2020-04-17 06:33:55,518 epoch 19 - iter 150/154 - loss 0.33764503 - samples/sec: 1957.50\n",
      "2020-04-17 06:33:55,664 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:55,665 EPOCH 19 done: loss 0.3393 - lr 0.0107\n",
      "2020-04-17 06:33:55,849 DEV : loss 0.4799238443374634 - score 0.8202\n",
      "2020-04-17 06:33:55,857 BAD EPOCHS (no improvement): 5\n",
      "2020-04-17 06:33:55,858 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:56,091 epoch 20 - iter 15/154 - loss 0.31601121 - samples/sec: 2070.32\n",
      "2020-04-17 06:33:56,404 epoch 20 - iter 30/154 - loss 0.33710589 - samples/sec: 2164.07\n",
      "2020-04-17 06:33:56,708 epoch 20 - iter 45/154 - loss 0.32827897 - samples/sec: 2234.34\n",
      "2020-04-17 06:33:57,027 epoch 20 - iter 60/154 - loss 0.32591268 - samples/sec: 2151.43\n",
      "2020-04-17 06:33:57,333 epoch 20 - iter 75/154 - loss 0.32349717 - samples/sec: 2238.20\n",
      "2020-04-17 06:33:57,629 epoch 20 - iter 90/154 - loss 0.32434454 - samples/sec: 2309.04\n",
      "2020-04-17 06:33:57,927 epoch 20 - iter 105/154 - loss 0.32732250 - samples/sec: 2314.47\n",
      "2020-04-17 06:33:58,316 epoch 20 - iter 120/154 - loss 0.33120634 - samples/sec: 1601.45\n",
      "2020-04-17 06:33:58,766 epoch 20 - iter 135/154 - loss 0.33149352 - samples/sec: 1348.57\n",
      "2020-04-17 06:33:59,163 epoch 20 - iter 150/154 - loss 0.32794582 - samples/sec: 1586.91\n",
      "2020-04-17 06:33:59,301 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:33:59,301 EPOCH 20 done: loss 0.3260 - lr 0.0107\n",
      "2020-04-17 06:33:59,494 DEV : loss 0.2923484742641449 - score 0.9009\n",
      "2020-04-17 06:33:59,502 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:34:00,014 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:00,250 epoch 21 - iter 15/154 - loss 0.30110619 - samples/sec: 2059.65\n",
      "2020-04-17 06:34:00,549 epoch 21 - iter 30/154 - loss 0.32799788 - samples/sec: 2274.68\n",
      "2020-04-17 06:34:00,850 epoch 21 - iter 45/154 - loss 0.32317902 - samples/sec: 2237.35\n",
      "2020-04-17 06:34:01,159 epoch 21 - iter 60/154 - loss 0.32195579 - samples/sec: 2192.13\n",
      "2020-04-17 06:34:01,464 epoch 21 - iter 75/154 - loss 0.31834277 - samples/sec: 2229.13\n",
      "2020-04-17 06:34:01,765 epoch 21 - iter 90/154 - loss 0.30848393 - samples/sec: 2270.47\n",
      "2020-04-17 06:34:02,114 epoch 21 - iter 105/154 - loss 0.31236740 - samples/sec: 1854.65\n",
      "2020-04-17 06:34:02,593 epoch 21 - iter 120/154 - loss 0.30992265 - samples/sec: 1280.59\n",
      "2020-04-17 06:34:02,975 epoch 21 - iter 135/154 - loss 0.30467700 - samples/sec: 1662.19\n",
      "2020-04-17 06:34:03,455 epoch 21 - iter 150/154 - loss 0.30290237 - samples/sec: 1240.26\n",
      "2020-04-17 06:34:03,600 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:03,600 EPOCH 21 done: loss 0.3058 - lr 0.0107\n",
      "2020-04-17 06:34:03,859 DEV : loss 0.2874864637851715 - score 0.9064\n",
      "2020-04-17 06:34:03,868 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:34:04,415 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:04,642 epoch 22 - iter 15/154 - loss 0.25267835 - samples/sec: 2133.50\n",
      "2020-04-17 06:34:04,955 epoch 22 - iter 30/154 - loss 0.28935345 - samples/sec: 2178.33\n",
      "2020-04-17 06:34:05,380 epoch 22 - iter 45/154 - loss 0.29990890 - samples/sec: 1449.95\n",
      "2020-04-17 06:34:05,734 epoch 22 - iter 60/154 - loss 0.31540078 - samples/sec: 1798.04\n",
      "2020-04-17 06:34:06,043 epoch 22 - iter 75/154 - loss 0.30717005 - samples/sec: 2198.29\n",
      "2020-04-17 06:34:06,356 epoch 22 - iter 90/154 - loss 0.30954355 - samples/sec: 2185.96\n",
      "2020-04-17 06:34:06,663 epoch 22 - iter 105/154 - loss 0.30711957 - samples/sec: 2234.21\n",
      "2020-04-17 06:34:06,960 epoch 22 - iter 120/154 - loss 0.30191439 - samples/sec: 2305.22\n",
      "2020-04-17 06:34:07,271 epoch 22 - iter 135/154 - loss 0.30233784 - samples/sec: 2167.27\n",
      "2020-04-17 06:34:07,572 epoch 22 - iter 150/154 - loss 0.29890021 - samples/sec: 2257.80\n",
      "2020-04-17 06:34:07,715 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:07,716 EPOCH 22 done: loss 0.2964 - lr 0.0107\n",
      "2020-04-17 06:34:07,906 DEV : loss 0.4149429500102997 - score 0.8385\n",
      "2020-04-17 06:34:07,914 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:34:07,915 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:08,154 epoch 23 - iter 15/154 - loss 0.34257223 - samples/sec: 2026.87\n",
      "2020-04-17 06:34:08,450 epoch 23 - iter 30/154 - loss 0.28883272 - samples/sec: 2324.85\n",
      "2020-04-17 06:34:08,749 epoch 23 - iter 45/154 - loss 0.29286192 - samples/sec: 2279.08\n",
      "2020-04-17 06:34:09,050 epoch 23 - iter 60/154 - loss 0.29526913 - samples/sec: 2267.72\n",
      "2020-04-17 06:34:09,354 epoch 23 - iter 75/154 - loss 0.28380216 - samples/sec: 2241.28\n",
      "2020-04-17 06:34:09,654 epoch 23 - iter 90/154 - loss 0.28262939 - samples/sec: 2273.22\n",
      "2020-04-17 06:34:09,953 epoch 23 - iter 105/154 - loss 0.28076144 - samples/sec: 2275.42\n",
      "2020-04-17 06:34:10,257 epoch 23 - iter 120/154 - loss 0.28143632 - samples/sec: 2242.95\n",
      "2020-04-17 06:34:10,556 epoch 23 - iter 135/154 - loss 0.27874332 - samples/sec: 2293.75\n",
      "2020-04-17 06:34:10,865 epoch 23 - iter 150/154 - loss 0.28112025 - samples/sec: 2186.20\n",
      "2020-04-17 06:34:11,007 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:11,008 EPOCH 23 done: loss 0.2808 - lr 0.0107\n",
      "2020-04-17 06:34:11,200 DEV : loss 0.30754750967025757 - score 0.8807\n",
      "2020-04-17 06:34:11,208 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:34:11,209 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:11,440 epoch 24 - iter 15/154 - loss 0.27470579 - samples/sec: 2089.92\n",
      "2020-04-17 06:34:11,743 epoch 24 - iter 30/154 - loss 0.28558522 - samples/sec: 2252.45\n",
      "2020-04-17 06:34:12,040 epoch 24 - iter 45/154 - loss 0.30178945 - samples/sec: 2344.90\n",
      "2020-04-17 06:34:12,358 epoch 24 - iter 60/154 - loss 0.28947428 - samples/sec: 2140.48\n",
      "2020-04-17 06:34:12,662 epoch 24 - iter 75/154 - loss 0.29649954 - samples/sec: 2229.01\n",
      "2020-04-17 06:34:12,963 epoch 24 - iter 90/154 - loss 0.28690283 - samples/sec: 2274.61\n",
      "2020-04-17 06:34:13,267 epoch 24 - iter 105/154 - loss 0.27618395 - samples/sec: 2233.35\n",
      "2020-04-17 06:34:13,573 epoch 24 - iter 120/154 - loss 0.26952851 - samples/sec: 2266.94\n",
      "2020-04-17 06:34:13,869 epoch 24 - iter 135/154 - loss 0.26703311 - samples/sec: 2330.40\n",
      "2020-04-17 06:34:14,173 epoch 24 - iter 150/154 - loss 0.26706909 - samples/sec: 2239.43\n",
      "2020-04-17 06:34:14,315 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:14,316 EPOCH 24 done: loss 0.2657 - lr 0.0107\n",
      "2020-04-17 06:34:14,502 DEV : loss 0.3079146444797516 - score 0.8936\n",
      "2020-04-17 06:34:14,510 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:34:14,511 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:14,738 epoch 25 - iter 15/154 - loss 0.24469743 - samples/sec: 2132.56\n",
      "2020-04-17 06:34:15,035 epoch 25 - iter 30/154 - loss 0.22145314 - samples/sec: 2313.01\n",
      "2020-04-17 06:34:15,339 epoch 25 - iter 45/154 - loss 0.24619964 - samples/sec: 2253.09\n",
      "2020-04-17 06:34:15,640 epoch 25 - iter 60/154 - loss 0.25420450 - samples/sec: 2242.96\n",
      "2020-04-17 06:34:15,939 epoch 25 - iter 75/154 - loss 0.27074029 - samples/sec: 2295.00\n",
      "2020-04-17 06:34:16,240 epoch 25 - iter 90/154 - loss 0.26510981 - samples/sec: 2264.85\n",
      "2020-04-17 06:34:16,542 epoch 25 - iter 105/154 - loss 0.27275790 - samples/sec: 2235.90\n",
      "2020-04-17 06:34:16,836 epoch 25 - iter 120/154 - loss 0.27000485 - samples/sec: 2322.18\n",
      "2020-04-17 06:34:17,135 epoch 25 - iter 135/154 - loss 0.27107273 - samples/sec: 2254.57\n",
      "2020-04-17 06:34:17,430 epoch 25 - iter 150/154 - loss 0.27056364 - samples/sec: 2297.53\n",
      "2020-04-17 06:34:17,566 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:17,566 EPOCH 25 done: loss 0.2687 - lr 0.0107\n",
      "2020-04-17 06:34:17,741 DEV : loss 0.28232541680336 - score 0.9193\n",
      "2020-04-17 06:34:17,749 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:34:18,270 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:18,492 epoch 26 - iter 15/154 - loss 0.25625276 - samples/sec: 2231.94\n",
      "2020-04-17 06:34:18,795 epoch 26 - iter 30/154 - loss 0.26285125 - samples/sec: 2296.45\n",
      "2020-04-17 06:34:19,088 epoch 26 - iter 45/154 - loss 0.24574052 - samples/sec: 2302.67\n",
      "2020-04-17 06:34:19,382 epoch 26 - iter 60/154 - loss 0.25281862 - samples/sec: 2301.09\n",
      "2020-04-17 06:34:19,677 epoch 26 - iter 75/154 - loss 0.25324710 - samples/sec: 2289.37\n",
      "2020-04-17 06:34:19,975 epoch 26 - iter 90/154 - loss 0.24928164 - samples/sec: 2267.12\n",
      "2020-04-17 06:34:20,272 epoch 26 - iter 105/154 - loss 0.24682858 - samples/sec: 2340.08\n",
      "2020-04-17 06:34:20,577 epoch 26 - iter 120/154 - loss 0.25159150 - samples/sec: 2222.91\n",
      "2020-04-17 06:34:20,875 epoch 26 - iter 135/154 - loss 0.24821784 - samples/sec: 2303.40\n",
      "2020-04-17 06:34:21,178 epoch 26 - iter 150/154 - loss 0.25155165 - samples/sec: 2241.67\n",
      "2020-04-17 06:34:21,318 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:21,319 EPOCH 26 done: loss 0.2499 - lr 0.0107\n",
      "2020-04-17 06:34:21,499 DEV : loss 0.32916831970214844 - score 0.8862\n",
      "2020-04-17 06:34:21,507 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:34:21,508 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:21,732 epoch 27 - iter 15/154 - loss 0.28892892 - samples/sec: 2162.78\n",
      "2020-04-17 06:34:22,037 epoch 27 - iter 30/154 - loss 0.26072718 - samples/sec: 2196.99\n",
      "2020-04-17 06:34:22,339 epoch 27 - iter 45/154 - loss 0.24653679 - samples/sec: 2223.11\n",
      "2020-04-17 06:34:22,640 epoch 27 - iter 60/154 - loss 0.25036426 - samples/sec: 2231.82\n",
      "2020-04-17 06:34:22,935 epoch 27 - iter 75/154 - loss 0.25614478 - samples/sec: 2286.26\n",
      "2020-04-17 06:34:23,255 epoch 27 - iter 90/154 - loss 0.26069523 - samples/sec: 2164.19\n",
      "2020-04-17 06:34:23,552 epoch 27 - iter 105/154 - loss 0.25495767 - samples/sec: 2264.35\n",
      "2020-04-17 06:34:23,844 epoch 27 - iter 120/154 - loss 0.25345369 - samples/sec: 2322.95\n",
      "2020-04-17 06:34:24,143 epoch 27 - iter 135/154 - loss 0.24964267 - samples/sec: 2247.76\n",
      "2020-04-17 06:34:24,443 epoch 27 - iter 150/154 - loss 0.24797881 - samples/sec: 2245.77\n",
      "2020-04-17 06:34:24,580 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:24,581 EPOCH 27 done: loss 0.2459 - lr 0.0107\n",
      "2020-04-17 06:34:24,758 DEV : loss 0.25444531440734863 - score 0.9156\n",
      "2020-04-17 06:34:24,766 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:34:24,767 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:25,001 epoch 28 - iter 15/154 - loss 0.29364326 - samples/sec: 2067.67\n",
      "2020-04-17 06:34:25,314 epoch 28 - iter 30/154 - loss 0.24676843 - samples/sec: 2117.25\n",
      "2020-04-17 06:34:25,627 epoch 28 - iter 45/154 - loss 0.25402011 - samples/sec: 2148.00\n",
      "2020-04-17 06:34:25,942 epoch 28 - iter 60/154 - loss 0.25602159 - samples/sec: 2105.55\n",
      "2020-04-17 06:34:26,279 epoch 28 - iter 75/154 - loss 0.25172826 - samples/sec: 1920.71\n",
      "2020-04-17 06:34:26,622 epoch 28 - iter 90/154 - loss 0.24766947 - samples/sec: 1889.50\n",
      "2020-04-17 06:34:26,953 epoch 28 - iter 105/154 - loss 0.24037300 - samples/sec: 1976.19\n",
      "2020-04-17 06:34:27,259 epoch 28 - iter 120/154 - loss 0.24480273 - samples/sec: 2172.47\n",
      "2020-04-17 06:34:27,558 epoch 28 - iter 135/154 - loss 0.24193995 - samples/sec: 2241.23\n",
      "2020-04-17 06:34:27,889 epoch 28 - iter 150/154 - loss 0.23885230 - samples/sec: 1958.98\n",
      "2020-04-17 06:34:28,048 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:28,049 EPOCH 28 done: loss 0.2408 - lr 0.0107\n",
      "2020-04-17 06:34:28,248 DEV : loss 0.2325022965669632 - score 0.9376\n",
      "2020-04-17 06:34:28,256 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:34:28,792 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:29,038 epoch 29 - iter 15/154 - loss 0.18302458 - samples/sec: 1977.27\n",
      "2020-04-17 06:34:29,336 epoch 29 - iter 30/154 - loss 0.20073844 - samples/sec: 2269.55\n",
      "2020-04-17 06:34:29,649 epoch 29 - iter 45/154 - loss 0.20708139 - samples/sec: 2085.90\n",
      "2020-04-17 06:34:30,002 epoch 29 - iter 60/154 - loss 0.20212926 - samples/sec: 1814.45\n",
      "2020-04-17 06:34:30,336 epoch 29 - iter 75/154 - loss 0.21423329 - samples/sec: 2001.97\n",
      "2020-04-17 06:34:30,649 epoch 29 - iter 90/154 - loss 0.20806350 - samples/sec: 2118.02\n",
      "2020-04-17 06:34:30,994 epoch 29 - iter 105/154 - loss 0.21690685 - samples/sec: 1852.12\n",
      "2020-04-17 06:34:31,328 epoch 29 - iter 120/154 - loss 0.22230991 - samples/sec: 1938.40\n",
      "2020-04-17 06:34:31,655 epoch 29 - iter 135/154 - loss 0.22342786 - samples/sec: 1985.87\n",
      "2020-04-17 06:34:31,959 epoch 29 - iter 150/154 - loss 0.22847314 - samples/sec: 2205.85\n",
      "2020-04-17 06:34:32,096 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:32,097 EPOCH 29 done: loss 0.2294 - lr 0.0107\n",
      "2020-04-17 06:34:32,268 DEV : loss 0.3172569274902344 - score 0.8936\n",
      "2020-04-17 06:34:32,276 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:34:32,277 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:32,491 epoch 30 - iter 15/154 - loss 0.16577067 - samples/sec: 2263.39\n",
      "2020-04-17 06:34:32,802 epoch 30 - iter 30/154 - loss 0.21821111 - samples/sec: 2182.77\n",
      "2020-04-17 06:34:33,108 epoch 30 - iter 45/154 - loss 0.22940705 - samples/sec: 2221.58\n",
      "2020-04-17 06:34:33,429 epoch 30 - iter 60/154 - loss 0.23404749 - samples/sec: 2192.13\n",
      "2020-04-17 06:34:33,731 epoch 30 - iter 75/154 - loss 0.22561023 - samples/sec: 2219.67\n",
      "2020-04-17 06:34:34,055 epoch 30 - iter 90/154 - loss 0.22132070 - samples/sec: 2019.41\n",
      "2020-04-17 06:34:34,378 epoch 30 - iter 105/154 - loss 0.21940758 - samples/sec: 2092.50\n",
      "2020-04-17 06:34:34,743 epoch 30 - iter 120/154 - loss 0.21552403 - samples/sec: 1742.11\n",
      "2020-04-17 06:34:35,080 epoch 30 - iter 135/154 - loss 0.22216209 - samples/sec: 1925.88\n",
      "2020-04-17 06:34:35,384 epoch 30 - iter 150/154 - loss 0.22063410 - samples/sec: 2244.62\n",
      "2020-04-17 06:34:35,522 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:35,523 EPOCH 30 done: loss 0.2197 - lr 0.0107\n",
      "2020-04-17 06:34:35,691 DEV : loss 0.25174590945243835 - score 0.9211\n",
      "2020-04-17 06:34:35,699 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:34:35,700 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:35,919 epoch 31 - iter 15/154 - loss 0.16839800 - samples/sec: 2210.27\n",
      "2020-04-17 06:34:36,224 epoch 31 - iter 30/154 - loss 0.18777162 - samples/sec: 2207.46\n",
      "2020-04-17 06:34:36,526 epoch 31 - iter 45/154 - loss 0.17812845 - samples/sec: 2215.27\n",
      "2020-04-17 06:34:36,824 epoch 31 - iter 60/154 - loss 0.17088828 - samples/sec: 2313.62\n",
      "2020-04-17 06:34:37,370 epoch 31 - iter 75/154 - loss 0.18110254 - samples/sec: 1100.32\n",
      "2020-04-17 06:34:37,707 epoch 31 - iter 90/154 - loss 0.19561003 - samples/sec: 2077.01\n",
      "2020-04-17 06:34:38,062 epoch 31 - iter 105/154 - loss 0.20277886 - samples/sec: 1822.21\n",
      "2020-04-17 06:34:38,366 epoch 31 - iter 120/154 - loss 0.20250626 - samples/sec: 2241.71\n",
      "2020-04-17 06:34:38,669 epoch 31 - iter 135/154 - loss 0.20916691 - samples/sec: 2258.99\n",
      "2020-04-17 06:34:38,995 epoch 31 - iter 150/154 - loss 0.20669286 - samples/sec: 2041.48\n",
      "2020-04-17 06:34:39,142 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:39,143 EPOCH 31 done: loss 0.2121 - lr 0.0107\n",
      "2020-04-17 06:34:39,319 DEV : loss 0.23928962647914886 - score 0.9229\n",
      "2020-04-17 06:34:39,328 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:34:39,328 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:39,543 epoch 32 - iter 15/154 - loss 0.25920943 - samples/sec: 2258.82\n",
      "2020-04-17 06:34:39,841 epoch 32 - iter 30/154 - loss 0.22199587 - samples/sec: 2301.39\n",
      "2020-04-17 06:34:40,146 epoch 32 - iter 45/154 - loss 0.20397420 - samples/sec: 2225.50\n",
      "2020-04-17 06:34:40,445 epoch 32 - iter 60/154 - loss 0.20147180 - samples/sec: 2280.12\n",
      "2020-04-17 06:34:40,746 epoch 32 - iter 75/154 - loss 0.21033527 - samples/sec: 2274.52\n",
      "2020-04-17 06:34:41,050 epoch 32 - iter 90/154 - loss 0.20503984 - samples/sec: 2242.03\n",
      "2020-04-17 06:34:41,352 epoch 32 - iter 105/154 - loss 0.20726602 - samples/sec: 2251.88\n",
      "2020-04-17 06:34:41,652 epoch 32 - iter 120/154 - loss 0.20314637 - samples/sec: 2279.23\n",
      "2020-04-17 06:34:41,950 epoch 32 - iter 135/154 - loss 0.20456472 - samples/sec: 2299.87\n",
      "2020-04-17 06:34:42,260 epoch 32 - iter 150/154 - loss 0.20449505 - samples/sec: 2188.97\n",
      "2020-04-17 06:34:42,402 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:42,402 EPOCH 32 done: loss 0.2067 - lr 0.0107\n",
      "2020-04-17 06:34:42,592 DEV : loss 0.2351827174425125 - score 0.9248\n",
      "2020-04-17 06:34:42,599 BAD EPOCHS (no improvement): 4\n",
      "2020-04-17 06:34:42,600 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:42,829 epoch 33 - iter 15/154 - loss 0.21032246 - samples/sec: 2118.11\n",
      "2020-04-17 06:34:43,143 epoch 33 - iter 30/154 - loss 0.21874634 - samples/sec: 2132.37\n",
      "2020-04-17 06:34:43,441 epoch 33 - iter 45/154 - loss 0.19701087 - samples/sec: 2297.30\n",
      "2020-04-17 06:34:43,744 epoch 33 - iter 60/154 - loss 0.20613509 - samples/sec: 2234.37\n",
      "2020-04-17 06:34:44,040 epoch 33 - iter 75/154 - loss 0.20272439 - samples/sec: 2308.68\n",
      "2020-04-17 06:34:44,337 epoch 33 - iter 90/154 - loss 0.20269414 - samples/sec: 2307.94\n",
      "2020-04-17 06:34:44,645 epoch 33 - iter 105/154 - loss 0.20870267 - samples/sec: 2187.31\n",
      "2020-04-17 06:34:44,970 epoch 33 - iter 120/154 - loss 0.20203649 - samples/sec: 2181.03\n",
      "2020-04-17 06:34:45,271 epoch 33 - iter 135/154 - loss 0.19869376 - samples/sec: 2263.59\n",
      "2020-04-17 06:34:45,580 epoch 33 - iter 150/154 - loss 0.19513567 - samples/sec: 2253.89\n",
      "2020-04-17 06:34:45,728 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:45,729 EPOCH 33 done: loss 0.1950 - lr 0.0107\n",
      "2020-04-17 06:34:45,911 DEV : loss 0.2289920598268509 - score 0.9376\n",
      "2020-04-17 06:34:45,919 BAD EPOCHS (no improvement): 5\n",
      "2020-04-17 06:34:46,453 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:46,674 epoch 34 - iter 15/154 - loss 0.22717110 - samples/sec: 2198.93\n",
      "2020-04-17 06:34:46,979 epoch 34 - iter 30/154 - loss 0.19384624 - samples/sec: 2285.30\n",
      "2020-04-17 06:34:47,308 epoch 34 - iter 45/154 - loss 0.19859599 - samples/sec: 2000.68\n",
      "2020-04-17 06:34:47,610 epoch 34 - iter 60/154 - loss 0.19422978 - samples/sec: 2307.24\n",
      "2020-04-17 06:34:47,915 epoch 34 - iter 75/154 - loss 0.19564837 - samples/sec: 2288.45\n",
      "2020-04-17 06:34:48,222 epoch 34 - iter 90/154 - loss 0.19960096 - samples/sec: 2260.41\n",
      "2020-04-17 06:34:48,512 epoch 34 - iter 105/154 - loss 0.19718342 - samples/sec: 2335.72\n",
      "2020-04-17 06:34:48,808 epoch 34 - iter 120/154 - loss 0.20138585 - samples/sec: 2325.38\n",
      "2020-04-17 06:34:49,117 epoch 34 - iter 135/154 - loss 0.19832221 - samples/sec: 2191.50\n",
      "2020-04-17 06:34:49,419 epoch 34 - iter 150/154 - loss 0.19545424 - samples/sec: 2261.29\n",
      "2020-04-17 06:34:49,558 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:49,558 EPOCH 34 done: loss 0.1960 - lr 0.0107\n",
      "2020-04-17 06:34:49,732 DEV : loss 0.2421444058418274 - score 0.9174\n",
      "Epoch    34: reducing learning rate of group 0 to 5.3576e-03.\n",
      "2020-04-17 06:34:49,740 BAD EPOCHS (no improvement): 6\n",
      "2020-04-17 06:34:49,746 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:49,965 epoch 35 - iter 15/154 - loss 0.16202679 - samples/sec: 2208.65\n",
      "2020-04-17 06:34:50,263 epoch 35 - iter 30/154 - loss 0.16221046 - samples/sec: 2296.94\n",
      "2020-04-17 06:34:50,561 epoch 35 - iter 45/154 - loss 0.15995905 - samples/sec: 2256.53\n",
      "2020-04-17 06:34:50,853 epoch 35 - iter 60/154 - loss 0.17054494 - samples/sec: 2321.16\n",
      "2020-04-17 06:34:51,155 epoch 35 - iter 75/154 - loss 0.17223435 - samples/sec: 2297.13\n",
      "2020-04-17 06:34:51,458 epoch 35 - iter 90/154 - loss 0.16755146 - samples/sec: 2309.99\n",
      "2020-04-17 06:34:51,755 epoch 35 - iter 105/154 - loss 0.17103956 - samples/sec: 2281.91\n",
      "2020-04-17 06:34:52,047 epoch 35 - iter 120/154 - loss 0.17464478 - samples/sec: 2332.94\n",
      "2020-04-17 06:34:52,339 epoch 35 - iter 135/154 - loss 0.17283286 - samples/sec: 2336.67\n",
      "2020-04-17 06:34:52,633 epoch 35 - iter 150/154 - loss 0.17050733 - samples/sec: 2313.74\n",
      "2020-04-17 06:34:52,768 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:52,769 EPOCH 35 done: loss 0.1714 - lr 0.0054\n",
      "2020-04-17 06:34:52,948 DEV : loss 0.22549374401569366 - score 0.9229\n",
      "2020-04-17 06:34:52,956 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:34:52,956 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:53,179 epoch 36 - iter 15/154 - loss 0.18000511 - samples/sec: 2174.32\n",
      "2020-04-17 06:34:53,469 epoch 36 - iter 30/154 - loss 0.15865704 - samples/sec: 2337.94\n",
      "2020-04-17 06:34:53,758 epoch 36 - iter 45/154 - loss 0.15749015 - samples/sec: 2345.30\n",
      "2020-04-17 06:34:54,050 epoch 36 - iter 60/154 - loss 0.16493557 - samples/sec: 2306.19\n",
      "2020-04-17 06:34:54,337 epoch 36 - iter 75/154 - loss 0.16352160 - samples/sec: 2364.86\n",
      "2020-04-17 06:34:54,624 epoch 36 - iter 90/154 - loss 0.16079530 - samples/sec: 2366.86\n",
      "2020-04-17 06:34:54,917 epoch 36 - iter 105/154 - loss 0.16205212 - samples/sec: 2316.81\n",
      "2020-04-17 06:34:55,214 epoch 36 - iter 120/154 - loss 0.16174647 - samples/sec: 2258.83\n",
      "2020-04-17 06:34:55,503 epoch 36 - iter 135/154 - loss 0.16138781 - samples/sec: 2347.50\n",
      "2020-04-17 06:34:55,800 epoch 36 - iter 150/154 - loss 0.16438239 - samples/sec: 2255.94\n",
      "2020-04-17 06:34:55,935 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:55,936 EPOCH 36 done: loss 0.1652 - lr 0.0054\n",
      "2020-04-17 06:34:56,116 DEV : loss 0.27710503339767456 - score 0.9156\n",
      "2020-04-17 06:34:56,124 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:34:56,125 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:56,347 epoch 37 - iter 15/154 - loss 0.15888457 - samples/sec: 2176.19\n",
      "2020-04-17 06:34:56,641 epoch 37 - iter 30/154 - loss 0.14579548 - samples/sec: 2295.76\n",
      "2020-04-17 06:34:56,931 epoch 37 - iter 45/154 - loss 0.15169453 - samples/sec: 2334.21\n",
      "2020-04-17 06:34:57,225 epoch 37 - iter 60/154 - loss 0.14928318 - samples/sec: 2299.99\n",
      "2020-04-17 06:34:57,519 epoch 37 - iter 75/154 - loss 0.16315918 - samples/sec: 2344.10\n",
      "2020-04-17 06:34:57,814 epoch 37 - iter 90/154 - loss 0.16292026 - samples/sec: 2303.91\n",
      "2020-04-17 06:34:58,110 epoch 37 - iter 105/154 - loss 0.16393572 - samples/sec: 2278.00\n",
      "2020-04-17 06:34:58,403 epoch 37 - iter 120/154 - loss 0.15605185 - samples/sec: 2332.80\n",
      "2020-04-17 06:34:58,698 epoch 37 - iter 135/154 - loss 0.16414825 - samples/sec: 2297.82\n",
      "2020-04-17 06:34:58,995 epoch 37 - iter 150/154 - loss 0.16321266 - samples/sec: 2281.18\n",
      "2020-04-17 06:34:59,135 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:59,136 EPOCH 37 done: loss 0.1628 - lr 0.0054\n",
      "2020-04-17 06:34:59,309 DEV : loss 0.21958327293395996 - score 0.9339\n",
      "2020-04-17 06:34:59,318 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:34:59,318 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:34:59,535 epoch 38 - iter 15/154 - loss 0.13919594 - samples/sec: 2230.83\n",
      "2020-04-17 06:34:59,833 epoch 38 - iter 30/154 - loss 0.16742651 - samples/sec: 2280.09\n",
      "2020-04-17 06:35:00,155 epoch 38 - iter 45/154 - loss 0.17193501 - samples/sec: 2175.40\n",
      "2020-04-17 06:35:00,452 epoch 38 - iter 60/154 - loss 0.17020397 - samples/sec: 2285.00\n",
      "2020-04-17 06:35:00,750 epoch 38 - iter 75/154 - loss 0.16417949 - samples/sec: 2264.09\n",
      "2020-04-17 06:35:01,057 epoch 38 - iter 90/154 - loss 0.16116055 - samples/sec: 2188.90\n",
      "2020-04-17 06:35:01,367 epoch 38 - iter 105/154 - loss 0.16326270 - samples/sec: 2152.46\n",
      "2020-04-17 06:35:01,665 epoch 38 - iter 120/154 - loss 0.16331133 - samples/sec: 2281.85\n",
      "2020-04-17 06:35:01,955 epoch 38 - iter 135/154 - loss 0.16415586 - samples/sec: 2344.72\n",
      "2020-04-17 06:35:02,251 epoch 38 - iter 150/154 - loss 0.16538966 - samples/sec: 2275.94\n",
      "2020-04-17 06:35:02,391 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:02,392 EPOCH 38 done: loss 0.1660 - lr 0.0054\n",
      "2020-04-17 06:35:02,570 DEV : loss 0.2183867245912552 - score 0.9413\n",
      "2020-04-17 06:35:02,578 BAD EPOCHS (no improvement): 0\n",
      "2020-04-17 06:35:03,116 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:03,345 epoch 39 - iter 15/154 - loss 0.15924927 - samples/sec: 2115.40\n",
      "2020-04-17 06:35:03,632 epoch 39 - iter 30/154 - loss 0.14581298 - samples/sec: 2360.74\n",
      "2020-04-17 06:35:03,957 epoch 39 - iter 45/154 - loss 0.14490844 - samples/sec: 2011.98\n",
      "2020-04-17 06:35:04,264 epoch 39 - iter 60/154 - loss 0.15192261 - samples/sec: 2188.82\n",
      "2020-04-17 06:35:04,567 epoch 39 - iter 75/154 - loss 0.15363374 - samples/sec: 2223.90\n",
      "2020-04-17 06:35:04,858 epoch 39 - iter 90/154 - loss 0.15510071 - samples/sec: 2343.25\n",
      "2020-04-17 06:35:05,152 epoch 39 - iter 105/154 - loss 0.15297283 - samples/sec: 2289.22\n",
      "2020-04-17 06:35:05,473 epoch 39 - iter 120/154 - loss 0.15272607 - samples/sec: 2029.69\n",
      "2020-04-17 06:35:05,776 epoch 39 - iter 135/154 - loss 0.15516104 - samples/sec: 2216.89\n",
      "2020-04-17 06:35:06,079 epoch 39 - iter 150/154 - loss 0.15954358 - samples/sec: 2221.72\n",
      "2020-04-17 06:35:06,221 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:06,222 EPOCH 39 done: loss 0.1591 - lr 0.0054\n",
      "2020-04-17 06:35:06,407 DEV : loss 0.21888461709022522 - score 0.9229\n",
      "2020-04-17 06:35:06,415 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:35:06,416 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:06,649 epoch 40 - iter 15/154 - loss 0.15714138 - samples/sec: 2084.59\n",
      "2020-04-17 06:35:06,982 epoch 40 - iter 30/154 - loss 0.15924171 - samples/sec: 1966.28\n",
      "2020-04-17 06:35:07,283 epoch 40 - iter 45/154 - loss 0.16044175 - samples/sec: 2256.89\n",
      "2020-04-17 06:35:07,611 epoch 40 - iter 60/154 - loss 0.16368643 - samples/sec: 2007.70\n",
      "2020-04-17 06:35:07,942 epoch 40 - iter 75/154 - loss 0.16467964 - samples/sec: 2014.29\n",
      "2020-04-17 06:35:08,277 epoch 40 - iter 90/154 - loss 0.16480228 - samples/sec: 1948.57\n",
      "2020-04-17 06:35:08,610 epoch 40 - iter 105/154 - loss 0.16155746 - samples/sec: 1938.26\n",
      "2020-04-17 06:35:08,909 epoch 40 - iter 120/154 - loss 0.15960189 - samples/sec: 2266.47\n",
      "2020-04-17 06:35:09,238 epoch 40 - iter 135/154 - loss 0.15826349 - samples/sec: 1982.50\n",
      "2020-04-17 06:35:09,534 epoch 40 - iter 150/154 - loss 0.15931874 - samples/sec: 2276.50\n",
      "2020-04-17 06:35:09,687 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:09,687 EPOCH 40 done: loss 0.1593 - lr 0.0054\n",
      "2020-04-17 06:35:09,928 DEV : loss 0.2265835553407669 - score 0.9413\n",
      "2020-04-17 06:35:09,936 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:35:10,472 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:10,727 epoch 41 - iter 15/154 - loss 0.16230639 - samples/sec: 1903.36\n",
      "2020-04-17 06:35:11,060 epoch 41 - iter 30/154 - loss 0.17120314 - samples/sec: 1966.09\n",
      "2020-04-17 06:35:11,392 epoch 41 - iter 45/154 - loss 0.16157492 - samples/sec: 1981.55\n",
      "2020-04-17 06:35:11,697 epoch 41 - iter 60/154 - loss 0.15178764 - samples/sec: 2202.76\n",
      "2020-04-17 06:35:12,005 epoch 41 - iter 75/154 - loss 0.15800014 - samples/sec: 2168.61\n",
      "2020-04-17 06:35:12,481 epoch 41 - iter 90/154 - loss 0.15670005 - samples/sec: 1240.93\n",
      "2020-04-17 06:35:12,937 epoch 41 - iter 105/154 - loss 0.15697994 - samples/sec: 1307.87\n",
      "2020-04-17 06:35:13,239 epoch 41 - iter 120/154 - loss 0.15290053 - samples/sec: 2207.50\n",
      "2020-04-17 06:35:13,540 epoch 41 - iter 135/154 - loss 0.15066093 - samples/sec: 2271.35\n",
      "2020-04-17 06:35:13,842 epoch 41 - iter 150/154 - loss 0.15266072 - samples/sec: 2242.01\n",
      "2020-04-17 06:35:13,989 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:13,989 EPOCH 41 done: loss 0.1532 - lr 0.0054\n",
      "2020-04-17 06:35:14,174 DEV : loss 0.22427630424499512 - score 0.9358\n",
      "2020-04-17 06:35:14,182 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:35:14,183 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:14,424 epoch 42 - iter 15/154 - loss 0.09459463 - samples/sec: 2000.62\n",
      "2020-04-17 06:35:14,718 epoch 42 - iter 30/154 - loss 0.11319196 - samples/sec: 2325.73\n",
      "2020-04-17 06:35:15,180 epoch 42 - iter 45/154 - loss 0.13549883 - samples/sec: 1290.30\n",
      "2020-04-17 06:35:15,653 epoch 42 - iter 60/154 - loss 0.14203714 - samples/sec: 1309.02\n",
      "2020-04-17 06:35:15,994 epoch 42 - iter 75/154 - loss 0.14182316 - samples/sec: 1889.18\n",
      "2020-04-17 06:35:16,362 epoch 42 - iter 90/154 - loss 0.15105488 - samples/sec: 1702.60\n",
      "2020-04-17 06:35:16,658 epoch 42 - iter 105/154 - loss 0.15256286 - samples/sec: 2305.53\n",
      "2020-04-17 06:35:16,960 epoch 42 - iter 120/154 - loss 0.15487752 - samples/sec: 2352.41\n",
      "2020-04-17 06:35:17,261 epoch 42 - iter 135/154 - loss 0.15849448 - samples/sec: 2245.60\n",
      "2020-04-17 06:35:17,561 epoch 42 - iter 150/154 - loss 0.15301248 - samples/sec: 2266.87\n",
      "2020-04-17 06:35:17,702 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:17,702 EPOCH 42 done: loss 0.1528 - lr 0.0054\n",
      "2020-04-17 06:35:17,916 DEV : loss 0.22424960136413574 - score 0.9394\n",
      "2020-04-17 06:35:17,923 BAD EPOCHS (no improvement): 4\n",
      "2020-04-17 06:35:17,924 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:18,166 epoch 43 - iter 15/154 - loss 0.16354132 - samples/sec: 1998.25\n",
      "2020-04-17 06:35:18,504 epoch 43 - iter 30/154 - loss 0.16388097 - samples/sec: 1925.69\n",
      "2020-04-17 06:35:18,812 epoch 43 - iter 45/154 - loss 0.16606699 - samples/sec: 2174.08\n",
      "2020-04-17 06:35:19,115 epoch 43 - iter 60/154 - loss 0.15501542 - samples/sec: 2247.07\n",
      "2020-04-17 06:35:19,411 epoch 43 - iter 75/154 - loss 0.14953062 - samples/sec: 2294.76\n",
      "2020-04-17 06:35:19,708 epoch 43 - iter 90/154 - loss 0.14147107 - samples/sec: 2280.30\n",
      "2020-04-17 06:35:19,996 epoch 43 - iter 105/154 - loss 0.14582546 - samples/sec: 2374.79\n",
      "2020-04-17 06:35:20,295 epoch 43 - iter 120/154 - loss 0.15023051 - samples/sec: 2272.13\n",
      "2020-04-17 06:35:20,609 epoch 43 - iter 135/154 - loss 0.15033000 - samples/sec: 2229.95\n",
      "2020-04-17 06:35:20,905 epoch 43 - iter 150/154 - loss 0.14743978 - samples/sec: 2296.52\n",
      "2020-04-17 06:35:21,043 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:21,043 EPOCH 43 done: loss 0.1454 - lr 0.0054\n",
      "2020-04-17 06:35:21,241 DEV : loss 0.22557908296585083 - score 0.9413\n",
      "2020-04-17 06:35:21,249 BAD EPOCHS (no improvement): 5\n",
      "2020-04-17 06:35:21,765 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:22,006 epoch 44 - iter 15/154 - loss 0.16957010 - samples/sec: 2012.51\n",
      "2020-04-17 06:35:22,310 epoch 44 - iter 30/154 - loss 0.16011250 - samples/sec: 2227.82\n",
      "2020-04-17 06:35:22,616 epoch 44 - iter 45/154 - loss 0.16592990 - samples/sec: 2199.86\n",
      "2020-04-17 06:35:22,916 epoch 44 - iter 60/154 - loss 0.16714146 - samples/sec: 2255.00\n",
      "2020-04-17 06:35:23,221 epoch 44 - iter 75/154 - loss 0.16132306 - samples/sec: 2207.42\n",
      "2020-04-17 06:35:23,520 epoch 44 - iter 90/154 - loss 0.15418430 - samples/sec: 2269.05\n",
      "2020-04-17 06:35:23,827 epoch 44 - iter 105/154 - loss 0.15191942 - samples/sec: 2189.44\n",
      "2020-04-17 06:35:24,127 epoch 44 - iter 120/154 - loss 0.15441326 - samples/sec: 2262.34\n",
      "2020-04-17 06:35:24,433 epoch 44 - iter 135/154 - loss 0.15706630 - samples/sec: 2204.90\n",
      "2020-04-17 06:35:24,737 epoch 44 - iter 150/154 - loss 0.15636862 - samples/sec: 2217.79\n",
      "2020-04-17 06:35:24,875 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:24,875 EPOCH 44 done: loss 0.1573 - lr 0.0054\n",
      "2020-04-17 06:35:25,054 DEV : loss 0.22557932138442993 - score 0.9321\n",
      "Epoch    44: reducing learning rate of group 0 to 2.6788e-03.\n",
      "2020-04-17 06:35:25,062 BAD EPOCHS (no improvement): 6\n",
      "2020-04-17 06:35:25,063 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:25,294 epoch 45 - iter 15/154 - loss 0.13748163 - samples/sec: 2094.73\n",
      "2020-04-17 06:35:25,603 epoch 45 - iter 30/154 - loss 0.13806002 - samples/sec: 2283.87\n",
      "2020-04-17 06:35:25,905 epoch 45 - iter 45/154 - loss 0.13976668 - samples/sec: 2226.89\n",
      "2020-04-17 06:35:26,215 epoch 45 - iter 60/154 - loss 0.13434464 - samples/sec: 2146.93\n",
      "2020-04-17 06:35:26,521 epoch 45 - iter 75/154 - loss 0.13659972 - samples/sec: 2181.85\n",
      "2020-04-17 06:35:26,826 epoch 45 - iter 90/154 - loss 0.13967932 - samples/sec: 2192.49\n",
      "2020-04-17 06:35:27,122 epoch 45 - iter 105/154 - loss 0.13630170 - samples/sec: 2267.52\n",
      "2020-04-17 06:35:27,432 epoch 45 - iter 120/154 - loss 0.13882510 - samples/sec: 2159.45\n",
      "2020-04-17 06:35:27,727 epoch 45 - iter 135/154 - loss 0.14075582 - samples/sec: 2287.44\n",
      "2020-04-17 06:35:28,027 epoch 45 - iter 150/154 - loss 0.14214420 - samples/sec: 2242.75\n",
      "2020-04-17 06:35:28,167 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:28,168 EPOCH 45 done: loss 0.1415 - lr 0.0027\n",
      "2020-04-17 06:35:28,358 DEV : loss 0.22335945069789886 - score 0.9413\n",
      "2020-04-17 06:35:28,368 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:35:28,902 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:29,134 epoch 46 - iter 15/154 - loss 0.10521183 - samples/sec: 2096.53\n",
      "2020-04-17 06:35:29,435 epoch 46 - iter 30/154 - loss 0.11378041 - samples/sec: 2223.69\n",
      "2020-04-17 06:35:29,740 epoch 46 - iter 45/154 - loss 0.12832184 - samples/sec: 2198.33\n",
      "2020-04-17 06:35:30,034 epoch 46 - iter 60/154 - loss 0.13362135 - samples/sec: 2297.09\n",
      "2020-04-17 06:35:30,330 epoch 46 - iter 75/154 - loss 0.12729347 - samples/sec: 2267.88\n",
      "2020-04-17 06:35:30,637 epoch 46 - iter 90/154 - loss 0.13903068 - samples/sec: 2196.71\n",
      "2020-04-17 06:35:30,932 epoch 46 - iter 105/154 - loss 0.13795200 - samples/sec: 2297.25\n",
      "2020-04-17 06:35:31,234 epoch 46 - iter 120/154 - loss 0.14164225 - samples/sec: 2224.53\n",
      "2020-04-17 06:35:31,531 epoch 46 - iter 135/154 - loss 0.14018682 - samples/sec: 2266.07\n",
      "2020-04-17 06:35:31,831 epoch 46 - iter 150/154 - loss 0.13801027 - samples/sec: 2221.77\n",
      "2020-04-17 06:35:31,971 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:31,972 EPOCH 46 done: loss 0.1371 - lr 0.0027\n",
      "2020-04-17 06:35:32,151 DEV : loss 0.21876361966133118 - score 0.9394\n",
      "2020-04-17 06:35:32,159 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:35:32,160 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:32,386 epoch 47 - iter 15/154 - loss 0.15381386 - samples/sec: 2136.08\n",
      "2020-04-17 06:35:32,688 epoch 47 - iter 30/154 - loss 0.16520462 - samples/sec: 2212.30\n",
      "2020-04-17 06:35:32,986 epoch 47 - iter 45/154 - loss 0.15367474 - samples/sec: 2262.00\n",
      "2020-04-17 06:35:33,286 epoch 47 - iter 60/154 - loss 0.14829784 - samples/sec: 2227.43\n",
      "2020-04-17 06:35:33,584 epoch 47 - iter 75/154 - loss 0.14164414 - samples/sec: 2249.19\n",
      "2020-04-17 06:35:33,882 epoch 47 - iter 90/154 - loss 0.14418096 - samples/sec: 2247.55\n",
      "2020-04-17 06:35:34,183 epoch 47 - iter 105/154 - loss 0.14078059 - samples/sec: 2229.09\n",
      "2020-04-17 06:35:34,474 epoch 47 - iter 120/154 - loss 0.13721852 - samples/sec: 2329.58\n",
      "2020-04-17 06:35:34,774 epoch 47 - iter 135/154 - loss 0.13919116 - samples/sec: 2225.89\n",
      "2020-04-17 06:35:35,073 epoch 47 - iter 150/154 - loss 0.14476145 - samples/sec: 2247.83\n",
      "2020-04-17 06:35:35,211 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:35,212 EPOCH 47 done: loss 0.1472 - lr 0.0027\n",
      "2020-04-17 06:35:35,390 DEV : loss 0.21705031394958496 - score 0.9321\n",
      "2020-04-17 06:35:35,398 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:35:35,404 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:35,628 epoch 48 - iter 15/154 - loss 0.10062041 - samples/sec: 2161.88\n",
      "2020-04-17 06:35:35,924 epoch 48 - iter 30/154 - loss 0.12470286 - samples/sec: 2273.76\n",
      "2020-04-17 06:35:36,225 epoch 48 - iter 45/154 - loss 0.13569048 - samples/sec: 2229.66\n",
      "2020-04-17 06:35:36,526 epoch 48 - iter 60/154 - loss 0.13336817 - samples/sec: 2224.25\n",
      "2020-04-17 06:35:36,824 epoch 48 - iter 75/154 - loss 0.13568366 - samples/sec: 2255.12\n",
      "2020-04-17 06:35:37,119 epoch 48 - iter 90/154 - loss 0.13509332 - samples/sec: 2284.11\n",
      "2020-04-17 06:35:37,421 epoch 48 - iter 105/154 - loss 0.13577682 - samples/sec: 2211.76\n",
      "2020-04-17 06:35:37,720 epoch 48 - iter 120/154 - loss 0.13130802 - samples/sec: 2241.79\n",
      "2020-04-17 06:35:38,016 epoch 48 - iter 135/154 - loss 0.13572623 - samples/sec: 2261.32\n",
      "2020-04-17 06:35:38,318 epoch 48 - iter 150/154 - loss 0.13468722 - samples/sec: 2222.03\n",
      "2020-04-17 06:35:38,454 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:38,455 EPOCH 48 done: loss 0.1351 - lr 0.0027\n",
      "2020-04-17 06:35:38,635 DEV : loss 0.2255455106496811 - score 0.9394\n",
      "2020-04-17 06:35:38,643 BAD EPOCHS (no improvement): 4\n",
      "2020-04-17 06:35:38,643 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:38,868 epoch 49 - iter 15/154 - loss 0.13405332 - samples/sec: 2150.20\n",
      "2020-04-17 06:35:39,176 epoch 49 - iter 30/154 - loss 0.13810030 - samples/sec: 2170.37\n",
      "2020-04-17 06:35:39,476 epoch 49 - iter 45/154 - loss 0.13217195 - samples/sec: 2234.43\n",
      "2020-04-17 06:35:39,772 epoch 49 - iter 60/154 - loss 0.13403725 - samples/sec: 2283.64\n",
      "2020-04-17 06:35:40,070 epoch 49 - iter 75/154 - loss 0.13784699 - samples/sec: 2251.97\n",
      "2020-04-17 06:35:40,374 epoch 49 - iter 90/154 - loss 0.13208835 - samples/sec: 2199.30\n",
      "2020-04-17 06:35:40,676 epoch 49 - iter 105/154 - loss 0.12924080 - samples/sec: 2241.68\n",
      "2020-04-17 06:35:40,972 epoch 49 - iter 120/154 - loss 0.12971566 - samples/sec: 2276.90\n",
      "2020-04-17 06:35:41,287 epoch 49 - iter 135/154 - loss 0.13486162 - samples/sec: 2215.29\n",
      "2020-04-17 06:35:41,593 epoch 49 - iter 150/154 - loss 0.13603149 - samples/sec: 2173.95\n",
      "2020-04-17 06:35:41,729 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:41,730 EPOCH 49 done: loss 0.1366 - lr 0.0027\n",
      "2020-04-17 06:35:41,906 DEV : loss 0.2169206291437149 - score 0.9376\n",
      "2020-04-17 06:35:41,914 BAD EPOCHS (no improvement): 5\n",
      "2020-04-17 06:35:41,915 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:42,145 epoch 50 - iter 15/154 - loss 0.12888265 - samples/sec: 2099.52\n",
      "2020-04-17 06:35:42,455 epoch 50 - iter 30/154 - loss 0.12644036 - samples/sec: 2152.68\n",
      "2020-04-17 06:35:42,753 epoch 50 - iter 45/154 - loss 0.12579607 - samples/sec: 2250.37\n",
      "2020-04-17 06:35:43,056 epoch 50 - iter 60/154 - loss 0.11981939 - samples/sec: 2211.08\n",
      "2020-04-17 06:35:43,353 epoch 50 - iter 75/154 - loss 0.12537190 - samples/sec: 2268.71\n",
      "2020-04-17 06:35:43,650 epoch 50 - iter 90/154 - loss 0.12535092 - samples/sec: 2268.46\n",
      "2020-04-17 06:35:43,951 epoch 50 - iter 105/154 - loss 0.12303693 - samples/sec: 2238.84\n",
      "2020-04-17 06:35:44,249 epoch 50 - iter 120/154 - loss 0.12166873 - samples/sec: 2252.22\n",
      "2020-04-17 06:35:44,550 epoch 50 - iter 135/154 - loss 0.12688312 - samples/sec: 2226.64\n",
      "2020-04-17 06:35:44,857 epoch 50 - iter 150/154 - loss 0.12699326 - samples/sec: 2165.83\n",
      "2020-04-17 06:35:45,000 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:45,000 EPOCH 50 done: loss 0.1288 - lr 0.0027\n",
      "2020-04-17 06:35:45,195 DEV : loss 0.21588845551013947 - score 0.9303\n",
      "Epoch    50: reducing learning rate of group 0 to 1.3394e-03.\n",
      "2020-04-17 06:35:45,203 BAD EPOCHS (no improvement): 6\n",
      "2020-04-17 06:35:45,204 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:45,432 epoch 51 - iter 15/154 - loss 0.17894416 - samples/sec: 2118.09\n",
      "2020-04-17 06:35:45,747 epoch 51 - iter 30/154 - loss 0.14990914 - samples/sec: 2219.13\n",
      "2020-04-17 06:35:46,059 epoch 51 - iter 45/154 - loss 0.14164280 - samples/sec: 2237.12\n",
      "2020-04-17 06:35:46,372 epoch 51 - iter 60/154 - loss 0.14138055 - samples/sec: 2219.03\n",
      "2020-04-17 06:35:46,691 epoch 51 - iter 75/154 - loss 0.13458621 - samples/sec: 2154.00\n",
      "2020-04-17 06:35:46,999 epoch 51 - iter 90/154 - loss 0.13394285 - samples/sec: 2245.69\n",
      "2020-04-17 06:35:47,306 epoch 51 - iter 105/154 - loss 0.13513011 - samples/sec: 2179.38\n",
      "2020-04-17 06:35:47,612 epoch 51 - iter 120/154 - loss 0.14039156 - samples/sec: 2221.16\n",
      "2020-04-17 06:35:47,915 epoch 51 - iter 135/154 - loss 0.13569265 - samples/sec: 2227.10\n",
      "2020-04-17 06:35:48,222 epoch 51 - iter 150/154 - loss 0.13414791 - samples/sec: 2176.08\n",
      "2020-04-17 06:35:48,364 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:48,365 EPOCH 51 done: loss 0.1321 - lr 0.0013\n",
      "2020-04-17 06:35:48,557 DEV : loss 0.21590419113636017 - score 0.9358\n",
      "2020-04-17 06:35:48,566 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:35:48,566 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:48,797 epoch 52 - iter 15/154 - loss 0.13149391 - samples/sec: 2100.44\n",
      "2020-04-17 06:35:49,103 epoch 52 - iter 30/154 - loss 0.13319712 - samples/sec: 2183.05\n",
      "2020-04-17 06:35:49,433 epoch 52 - iter 45/154 - loss 0.13244706 - samples/sec: 2101.29\n",
      "2020-04-17 06:35:49,929 epoch 52 - iter 60/154 - loss 0.13565546 - samples/sec: 1175.35\n",
      "2020-04-17 06:35:50,221 epoch 52 - iter 75/154 - loss 0.13796824 - samples/sec: 2333.33\n",
      "2020-04-17 06:35:50,517 epoch 52 - iter 90/154 - loss 0.13925742 - samples/sec: 2298.01\n",
      "2020-04-17 06:35:51,008 epoch 52 - iter 105/154 - loss 0.13814270 - samples/sec: 1187.87\n",
      "2020-04-17 06:35:51,457 epoch 52 - iter 120/154 - loss 0.13634581 - samples/sec: 1324.71\n",
      "2020-04-17 06:35:51,937 epoch 52 - iter 135/154 - loss 0.13711628 - samples/sec: 1224.95\n",
      "2020-04-17 06:35:52,383 epoch 52 - iter 150/154 - loss 0.13978141 - samples/sec: 1350.42\n",
      "2020-04-17 06:35:52,540 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:52,541 EPOCH 52 done: loss 0.1376 - lr 0.0013\n",
      "2020-04-17 06:35:52,845 DEV : loss 0.2231007218360901 - score 0.9376\n",
      "2020-04-17 06:35:52,854 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:35:52,854 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:53,205 epoch 53 - iter 15/154 - loss 0.19211192 - samples/sec: 1378.85\n",
      "2020-04-17 06:35:53,543 epoch 53 - iter 30/154 - loss 0.15926202 - samples/sec: 1913.12\n",
      "2020-04-17 06:35:53,889 epoch 53 - iter 45/154 - loss 0.14807425 - samples/sec: 1883.35\n",
      "2020-04-17 06:35:54,187 epoch 53 - iter 60/154 - loss 0.14275306 - samples/sec: 2269.85\n",
      "2020-04-17 06:35:54,493 epoch 53 - iter 75/154 - loss 0.13970662 - samples/sec: 2324.68\n",
      "2020-04-17 06:35:54,792 epoch 53 - iter 90/154 - loss 0.13134539 - samples/sec: 2266.05\n",
      "2020-04-17 06:35:55,088 epoch 53 - iter 105/154 - loss 0.12773956 - samples/sec: 2278.49\n",
      "2020-04-17 06:35:55,384 epoch 53 - iter 120/154 - loss 0.12783802 - samples/sec: 2292.01\n",
      "2020-04-17 06:35:55,679 epoch 53 - iter 135/154 - loss 0.12836828 - samples/sec: 2288.02\n",
      "2020-04-17 06:35:55,975 epoch 53 - iter 150/154 - loss 0.12739462 - samples/sec: 2294.61\n",
      "2020-04-17 06:35:56,113 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:56,114 EPOCH 53 done: loss 0.1275 - lr 0.0013\n",
      "2020-04-17 06:35:56,291 DEV : loss 0.21759073436260223 - score 0.9339\n",
      "2020-04-17 06:35:56,300 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:35:56,300 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:56,539 epoch 54 - iter 15/154 - loss 0.18020019 - samples/sec: 2023.57\n",
      "2020-04-17 06:35:56,832 epoch 54 - iter 30/154 - loss 0.15004371 - samples/sec: 2327.16\n",
      "2020-04-17 06:35:57,137 epoch 54 - iter 45/154 - loss 0.15391953 - samples/sec: 2200.15\n",
      "2020-04-17 06:35:57,442 epoch 54 - iter 60/154 - loss 0.14100214 - samples/sec: 2218.84\n",
      "2020-04-17 06:35:57,736 epoch 54 - iter 75/154 - loss 0.13182492 - samples/sec: 2317.83\n",
      "2020-04-17 06:35:58,033 epoch 54 - iter 90/154 - loss 0.12588881 - samples/sec: 2301.55\n",
      "2020-04-17 06:35:58,336 epoch 54 - iter 105/154 - loss 0.12674976 - samples/sec: 2211.35\n",
      "2020-04-17 06:35:58,634 epoch 54 - iter 120/154 - loss 0.12760213 - samples/sec: 2293.69\n",
      "2020-04-17 06:35:58,926 epoch 54 - iter 135/154 - loss 0.12890164 - samples/sec: 2353.83\n",
      "2020-04-17 06:35:59,229 epoch 54 - iter 150/154 - loss 0.12825461 - samples/sec: 2228.79\n",
      "2020-04-17 06:35:59,368 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:59,369 EPOCH 54 done: loss 0.1274 - lr 0.0013\n",
      "2020-04-17 06:35:59,553 DEV : loss 0.21600408852100372 - score 0.9339\n",
      "2020-04-17 06:35:59,561 BAD EPOCHS (no improvement): 4\n",
      "2020-04-17 06:35:59,561 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:35:59,776 epoch 55 - iter 15/154 - loss 0.14734178 - samples/sec: 2250.72\n",
      "2020-04-17 06:36:00,078 epoch 55 - iter 30/154 - loss 0.13132267 - samples/sec: 2241.62\n",
      "2020-04-17 06:36:00,374 epoch 55 - iter 45/154 - loss 0.12962801 - samples/sec: 2300.60\n",
      "2020-04-17 06:36:00,675 epoch 55 - iter 60/154 - loss 0.12358872 - samples/sec: 2242.22\n",
      "2020-04-17 06:36:00,966 epoch 55 - iter 75/154 - loss 0.12889396 - samples/sec: 2359.73\n",
      "2020-04-17 06:36:01,263 epoch 55 - iter 90/154 - loss 0.13004763 - samples/sec: 2290.31\n",
      "2020-04-17 06:36:01,556 epoch 55 - iter 105/154 - loss 0.13363920 - samples/sec: 2336.21\n",
      "2020-04-17 06:36:01,845 epoch 55 - iter 120/154 - loss 0.13734065 - samples/sec: 2378.23\n",
      "2020-04-17 06:36:02,138 epoch 55 - iter 135/154 - loss 0.13565068 - samples/sec: 2303.84\n",
      "2020-04-17 06:36:02,448 epoch 55 - iter 150/154 - loss 0.13347351 - samples/sec: 2261.14\n",
      "2020-04-17 06:36:02,585 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:02,586 EPOCH 55 done: loss 0.1332 - lr 0.0013\n",
      "2020-04-17 06:36:02,760 DEV : loss 0.22000248730182648 - score 0.9413\n",
      "2020-04-17 06:36:02,768 BAD EPOCHS (no improvement): 5\n",
      "2020-04-17 06:36:03,283 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:03,507 epoch 56 - iter 15/154 - loss 0.15169111 - samples/sec: 2164.50\n",
      "2020-04-17 06:36:03,804 epoch 56 - iter 30/154 - loss 0.14586605 - samples/sec: 2287.19\n",
      "2020-04-17 06:36:04,110 epoch 56 - iter 45/154 - loss 0.13735557 - samples/sec: 2206.69\n",
      "2020-04-17 06:36:04,414 epoch 56 - iter 60/154 - loss 0.13703831 - samples/sec: 2232.57\n",
      "2020-04-17 06:36:04,711 epoch 56 - iter 75/154 - loss 0.12896520 - samples/sec: 2300.69\n",
      "2020-04-17 06:36:05,006 epoch 56 - iter 90/154 - loss 0.12232094 - samples/sec: 2321.64\n",
      "2020-04-17 06:36:05,303 epoch 56 - iter 105/154 - loss 0.12579728 - samples/sec: 2304.58\n",
      "2020-04-17 06:36:05,604 epoch 56 - iter 120/154 - loss 0.12462175 - samples/sec: 2262.92\n",
      "2020-04-17 06:36:05,899 epoch 56 - iter 135/154 - loss 0.12384015 - samples/sec: 2325.41\n",
      "2020-04-17 06:36:06,210 epoch 56 - iter 150/154 - loss 0.12106477 - samples/sec: 2159.70\n",
      "2020-04-17 06:36:06,358 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:06,359 EPOCH 56 done: loss 0.1221 - lr 0.0013\n",
      "2020-04-17 06:36:06,727 DEV : loss 0.21604783833026886 - score 0.9339\n",
      "Epoch    56: reducing learning rate of group 0 to 6.6970e-04.\n",
      "2020-04-17 06:36:06,735 BAD EPOCHS (no improvement): 6\n",
      "2020-04-17 06:36:06,736 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:07,027 epoch 57 - iter 15/154 - loss 0.13295505 - samples/sec: 1660.50\n",
      "2020-04-17 06:36:07,479 epoch 57 - iter 30/154 - loss 0.13591871 - samples/sec: 1334.15\n",
      "2020-04-17 06:36:07,897 epoch 57 - iter 45/154 - loss 0.13472026 - samples/sec: 1462.39\n",
      "2020-04-17 06:36:08,298 epoch 57 - iter 60/154 - loss 0.13391939 - samples/sec: 1537.54\n",
      "2020-04-17 06:36:08,743 epoch 57 - iter 75/154 - loss 0.12657811 - samples/sec: 1355.15\n",
      "2020-04-17 06:36:09,048 epoch 57 - iter 90/154 - loss 0.12621309 - samples/sec: 2241.11\n",
      "2020-04-17 06:36:09,351 epoch 57 - iter 105/154 - loss 0.12772129 - samples/sec: 2257.60\n",
      "2020-04-17 06:36:09,643 epoch 57 - iter 120/154 - loss 0.12647438 - samples/sec: 2320.11\n",
      "2020-04-17 06:36:09,934 epoch 57 - iter 135/154 - loss 0.12779886 - samples/sec: 2340.95\n",
      "2020-04-17 06:36:10,234 epoch 57 - iter 150/154 - loss 0.12622763 - samples/sec: 2261.14\n",
      "2020-04-17 06:36:10,386 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:10,387 EPOCH 57 done: loss 0.1257 - lr 0.0007\n",
      "2020-04-17 06:36:10,569 DEV : loss 0.21604976058006287 - score 0.9321\n",
      "2020-04-17 06:36:10,577 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:36:10,578 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:10,806 epoch 58 - iter 15/154 - loss 0.10955853 - samples/sec: 2127.39\n",
      "2020-04-17 06:36:11,097 epoch 58 - iter 30/154 - loss 0.12436263 - samples/sec: 2350.90\n",
      "2020-04-17 06:36:11,396 epoch 58 - iter 45/154 - loss 0.12673938 - samples/sec: 2266.31\n",
      "2020-04-17 06:36:11,701 epoch 58 - iter 60/154 - loss 0.13339097 - samples/sec: 2207.85\n",
      "2020-04-17 06:36:12,007 epoch 58 - iter 75/154 - loss 0.12403048 - samples/sec: 2193.21\n",
      "2020-04-17 06:36:12,306 epoch 58 - iter 90/154 - loss 0.12440822 - samples/sec: 2264.72\n",
      "2020-04-17 06:36:12,622 epoch 58 - iter 105/154 - loss 0.12308960 - samples/sec: 2218.77\n",
      "2020-04-17 06:36:12,924 epoch 58 - iter 120/154 - loss 0.12095327 - samples/sec: 2240.75\n",
      "2020-04-17 06:36:13,239 epoch 58 - iter 135/154 - loss 0.12106112 - samples/sec: 2101.28\n",
      "2020-04-17 06:36:13,551 epoch 58 - iter 150/154 - loss 0.12002862 - samples/sec: 2155.44\n",
      "2020-04-17 06:36:13,694 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:13,694 EPOCH 58 done: loss 0.1201 - lr 0.0007\n",
      "2020-04-17 06:36:13,888 DEV : loss 0.21611915528774261 - score 0.9358\n",
      "2020-04-17 06:36:13,896 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:36:13,897 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:14,139 epoch 59 - iter 15/154 - loss 0.17461918 - samples/sec: 1996.93\n",
      "2020-04-17 06:36:14,443 epoch 59 - iter 30/154 - loss 0.15245168 - samples/sec: 2207.04\n",
      "2020-04-17 06:36:14,746 epoch 59 - iter 45/154 - loss 0.14108228 - samples/sec: 2223.25\n",
      "2020-04-17 06:36:15,052 epoch 59 - iter 60/154 - loss 0.13563477 - samples/sec: 2206.25\n",
      "2020-04-17 06:36:15,357 epoch 59 - iter 75/154 - loss 0.13217759 - samples/sec: 2225.40\n",
      "2020-04-17 06:36:15,673 epoch 59 - iter 90/154 - loss 0.12697492 - samples/sec: 2218.84\n",
      "2020-04-17 06:36:15,974 epoch 59 - iter 105/154 - loss 0.12606147 - samples/sec: 2239.94\n",
      "2020-04-17 06:36:16,278 epoch 59 - iter 120/154 - loss 0.12905997 - samples/sec: 2202.83\n",
      "2020-04-17 06:36:16,576 epoch 59 - iter 135/154 - loss 0.12755183 - samples/sec: 2264.69\n",
      "2020-04-17 06:36:16,892 epoch 59 - iter 150/154 - loss 0.12787254 - samples/sec: 2094.55\n",
      "2020-04-17 06:36:17,038 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:17,038 EPOCH 59 done: loss 0.1267 - lr 0.0007\n",
      "2020-04-17 06:36:17,248 DEV : loss 0.21855446696281433 - score 0.9413\n",
      "2020-04-17 06:36:17,256 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:36:17,798 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:18,032 epoch 60 - iter 15/154 - loss 0.12690959 - samples/sec: 2078.67\n",
      "2020-04-17 06:36:18,345 epoch 60 - iter 30/154 - loss 0.11703125 - samples/sec: 2092.83\n",
      "2020-04-17 06:36:18,658 epoch 60 - iter 45/154 - loss 0.11412253 - samples/sec: 2122.41\n",
      "2020-04-17 06:36:18,974 epoch 60 - iter 60/154 - loss 0.11295606 - samples/sec: 2101.05\n",
      "2020-04-17 06:36:19,283 epoch 60 - iter 75/154 - loss 0.11697063 - samples/sec: 2177.86\n",
      "2020-04-17 06:36:19,595 epoch 60 - iter 90/154 - loss 0.12044874 - samples/sec: 2153.72\n",
      "2020-04-17 06:36:19,907 epoch 60 - iter 105/154 - loss 0.12075154 - samples/sec: 2125.33\n",
      "2020-04-17 06:36:20,211 epoch 60 - iter 120/154 - loss 0.12187117 - samples/sec: 2193.32\n",
      "2020-04-17 06:36:20,519 epoch 60 - iter 135/154 - loss 0.12213811 - samples/sec: 2177.75\n",
      "2020-04-17 06:36:20,826 epoch 60 - iter 150/154 - loss 0.12583485 - samples/sec: 2173.68\n",
      "2020-04-17 06:36:20,968 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:20,969 EPOCH 60 done: loss 0.1237 - lr 0.0007\n",
      "2020-04-17 06:36:21,150 DEV : loss 0.21520371735095978 - score 0.9321\n",
      "2020-04-17 06:36:21,158 BAD EPOCHS (no improvement): 4\n",
      "2020-04-17 06:36:21,159 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:21,387 epoch 61 - iter 15/154 - loss 0.10661759 - samples/sec: 2117.95\n",
      "2020-04-17 06:36:21,692 epoch 61 - iter 30/154 - loss 0.10836218 - samples/sec: 2218.70\n",
      "2020-04-17 06:36:22,006 epoch 61 - iter 45/154 - loss 0.11040601 - samples/sec: 2144.03\n",
      "2020-04-17 06:36:22,321 epoch 61 - iter 60/154 - loss 0.12213675 - samples/sec: 2161.88\n",
      "2020-04-17 06:36:22,645 epoch 61 - iter 75/154 - loss 0.12165532 - samples/sec: 2175.50\n",
      "2020-04-17 06:36:22,953 epoch 61 - iter 90/154 - loss 0.12024377 - samples/sec: 2169.16\n",
      "2020-04-17 06:36:23,262 epoch 61 - iter 105/154 - loss 0.12079901 - samples/sec: 2169.90\n",
      "2020-04-17 06:36:23,566 epoch 61 - iter 120/154 - loss 0.11900754 - samples/sec: 2247.04\n",
      "2020-04-17 06:36:23,881 epoch 61 - iter 135/154 - loss 0.11725389 - samples/sec: 2111.66\n",
      "2020-04-17 06:36:24,189 epoch 61 - iter 150/154 - loss 0.11747485 - samples/sec: 2183.81\n",
      "2020-04-17 06:36:24,339 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:24,340 EPOCH 61 done: loss 0.1172 - lr 0.0007\n",
      "2020-04-17 06:36:24,519 DEV : loss 0.21459460258483887 - score 0.9339\n",
      "2020-04-17 06:36:24,527 BAD EPOCHS (no improvement): 5\n",
      "2020-04-17 06:36:24,528 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:24,754 epoch 62 - iter 15/154 - loss 0.12191246 - samples/sec: 2140.24\n",
      "2020-04-17 06:36:25,067 epoch 62 - iter 30/154 - loss 0.12199779 - samples/sec: 2140.84\n",
      "2020-04-17 06:36:25,379 epoch 62 - iter 45/154 - loss 0.12947298 - samples/sec: 2153.14\n",
      "2020-04-17 06:36:25,690 epoch 62 - iter 60/154 - loss 0.13385901 - samples/sec: 2164.04\n",
      "2020-04-17 06:36:26,006 epoch 62 - iter 75/154 - loss 0.13092687 - samples/sec: 2115.92\n",
      "2020-04-17 06:36:26,314 epoch 62 - iter 90/154 - loss 0.12865310 - samples/sec: 2191.92\n",
      "2020-04-17 06:36:26,619 epoch 62 - iter 105/154 - loss 0.12488185 - samples/sec: 2215.87\n",
      "2020-04-17 06:36:26,933 epoch 62 - iter 120/154 - loss 0.12781561 - samples/sec: 2124.85\n",
      "2020-04-17 06:36:27,233 epoch 62 - iter 135/154 - loss 0.12885119 - samples/sec: 2265.01\n",
      "2020-04-17 06:36:27,546 epoch 62 - iter 150/154 - loss 0.12956508 - samples/sec: 2142.49\n",
      "2020-04-17 06:36:27,688 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:27,689 EPOCH 62 done: loss 0.1286 - lr 0.0007\n",
      "2020-04-17 06:36:27,874 DEV : loss 0.21596816182136536 - score 0.9376\n",
      "Epoch    62: reducing learning rate of group 0 to 3.3485e-04.\n",
      "2020-04-17 06:36:27,882 BAD EPOCHS (no improvement): 6\n",
      "2020-04-17 06:36:27,883 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:28,100 epoch 63 - iter 15/154 - loss 0.10358939 - samples/sec: 2234.86\n",
      "2020-04-17 06:36:28,417 epoch 63 - iter 30/154 - loss 0.11500007 - samples/sec: 2111.09\n",
      "2020-04-17 06:36:28,722 epoch 63 - iter 45/154 - loss 0.12679011 - samples/sec: 2221.98\n",
      "2020-04-17 06:36:29,035 epoch 63 - iter 60/154 - loss 0.13172501 - samples/sec: 2150.51\n",
      "2020-04-17 06:36:29,352 epoch 63 - iter 75/154 - loss 0.12688554 - samples/sec: 2092.99\n",
      "2020-04-17 06:36:29,661 epoch 63 - iter 90/154 - loss 0.12577297 - samples/sec: 2176.23\n",
      "2020-04-17 06:36:29,971 epoch 63 - iter 105/154 - loss 0.12185138 - samples/sec: 2170.94\n",
      "2020-04-17 06:36:30,283 epoch 63 - iter 120/154 - loss 0.12340178 - samples/sec: 2155.95\n",
      "2020-04-17 06:36:30,599 epoch 63 - iter 135/154 - loss 0.12382492 - samples/sec: 2156.61\n",
      "2020-04-17 06:36:30,917 epoch 63 - iter 150/154 - loss 0.12536388 - samples/sec: 2094.88\n",
      "2020-04-17 06:36:31,059 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:31,060 EPOCH 63 done: loss 0.1254 - lr 0.0003\n",
      "2020-04-17 06:36:31,237 DEV : loss 0.2156294286251068 - score 0.9339\n",
      "2020-04-17 06:36:31,245 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:36:31,246 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:31,473 epoch 64 - iter 15/154 - loss 0.14103713 - samples/sec: 2133.14\n",
      "2020-04-17 06:36:31,777 epoch 64 - iter 30/154 - loss 0.11730322 - samples/sec: 2193.64\n",
      "2020-04-17 06:36:32,089 epoch 64 - iter 45/154 - loss 0.11817811 - samples/sec: 2156.21\n",
      "2020-04-17 06:36:32,406 epoch 64 - iter 60/154 - loss 0.11959560 - samples/sec: 2099.17\n",
      "2020-04-17 06:36:32,708 epoch 64 - iter 75/154 - loss 0.12576979 - samples/sec: 2226.81\n",
      "2020-04-17 06:36:33,032 epoch 64 - iter 90/154 - loss 0.12662993 - samples/sec: 2166.22\n",
      "2020-04-17 06:36:33,345 epoch 64 - iter 105/154 - loss 0.12281119 - samples/sec: 2128.44\n",
      "2020-04-17 06:36:33,650 epoch 64 - iter 120/154 - loss 0.12187169 - samples/sec: 2220.71\n",
      "2020-04-17 06:36:33,961 epoch 64 - iter 135/154 - loss 0.12104402 - samples/sec: 2143.56\n",
      "2020-04-17 06:36:34,269 epoch 64 - iter 150/154 - loss 0.12250924 - samples/sec: 2143.30\n",
      "2020-04-17 06:36:34,410 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:34,411 EPOCH 64 done: loss 0.1212 - lr 0.0003\n",
      "2020-04-17 06:36:34,585 DEV : loss 0.21565298736095428 - score 0.9321\n",
      "2020-04-17 06:36:34,594 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:36:34,594 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:34,822 epoch 65 - iter 15/154 - loss 0.13610737 - samples/sec: 2126.41\n",
      "2020-04-17 06:36:35,130 epoch 65 - iter 30/154 - loss 0.13251967 - samples/sec: 2156.35\n",
      "2020-04-17 06:36:35,439 epoch 65 - iter 45/154 - loss 0.12947851 - samples/sec: 2146.51\n",
      "2020-04-17 06:36:35,746 epoch 65 - iter 60/154 - loss 0.13169216 - samples/sec: 2174.53\n",
      "2020-04-17 06:36:36,052 epoch 65 - iter 75/154 - loss 0.13184682 - samples/sec: 2191.86\n",
      "2020-04-17 06:36:36,358 epoch 65 - iter 90/154 - loss 0.13023825 - samples/sec: 2178.33\n",
      "2020-04-17 06:36:36,669 epoch 65 - iter 105/154 - loss 0.12833797 - samples/sec: 2156.48\n",
      "2020-04-17 06:36:36,981 epoch 65 - iter 120/154 - loss 0.12597076 - samples/sec: 2150.04\n",
      "2020-04-17 06:36:37,289 epoch 65 - iter 135/154 - loss 0.12663940 - samples/sec: 2177.78\n",
      "2020-04-17 06:36:37,599 epoch 65 - iter 150/154 - loss 0.12641719 - samples/sec: 2165.96\n",
      "2020-04-17 06:36:37,742 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:37,742 EPOCH 65 done: loss 0.1280 - lr 0.0003\n",
      "2020-04-17 06:36:37,939 DEV : loss 0.2169482558965683 - score 0.9394\n",
      "2020-04-17 06:36:37,948 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:36:37,949 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:38,175 epoch 66 - iter 15/154 - loss 0.11810579 - samples/sec: 2135.37\n",
      "2020-04-17 06:36:38,498 epoch 66 - iter 30/154 - loss 0.12610420 - samples/sec: 2086.97\n",
      "2020-04-17 06:36:38,829 epoch 66 - iter 45/154 - loss 0.12144423 - samples/sec: 2001.72\n",
      "2020-04-17 06:36:39,168 epoch 66 - iter 60/154 - loss 0.12199944 - samples/sec: 1958.13\n",
      "2020-04-17 06:36:39,497 epoch 66 - iter 75/154 - loss 0.12296896 - samples/sec: 2011.97\n",
      "2020-04-17 06:36:39,845 epoch 66 - iter 90/154 - loss 0.11918199 - samples/sec: 1880.88\n",
      "2020-04-17 06:36:40,174 epoch 66 - iter 105/154 - loss 0.11581488 - samples/sec: 2090.70\n",
      "2020-04-17 06:36:40,722 epoch 66 - iter 120/154 - loss 0.11337806 - samples/sec: 1080.33\n",
      "2020-04-17 06:36:41,199 epoch 66 - iter 135/154 - loss 0.11252392 - samples/sec: 1239.50\n",
      "2020-04-17 06:36:41,677 epoch 66 - iter 150/154 - loss 0.11713129 - samples/sec: 1245.54\n",
      "2020-04-17 06:36:41,856 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:41,857 EPOCH 66 done: loss 0.1217 - lr 0.0003\n",
      "2020-04-17 06:36:42,132 DEV : loss 0.21824979782104492 - score 0.9413\n",
      "2020-04-17 06:36:42,141 BAD EPOCHS (no improvement): 4\n",
      "2020-04-17 06:36:42,692 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:43,036 epoch 67 - iter 15/154 - loss 0.13648001 - samples/sec: 1411.62\n",
      "2020-04-17 06:36:43,339 epoch 67 - iter 30/154 - loss 0.13926264 - samples/sec: 2250.65\n",
      "2020-04-17 06:36:43,641 epoch 67 - iter 45/154 - loss 0.12801109 - samples/sec: 2248.36\n",
      "2020-04-17 06:36:43,938 epoch 67 - iter 60/154 - loss 0.12325342 - samples/sec: 2301.46\n",
      "2020-04-17 06:36:44,237 epoch 67 - iter 75/154 - loss 0.13028207 - samples/sec: 2281.85\n",
      "2020-04-17 06:36:44,535 epoch 67 - iter 90/154 - loss 0.12837297 - samples/sec: 2290.11\n",
      "2020-04-17 06:36:44,833 epoch 67 - iter 105/154 - loss 0.12915902 - samples/sec: 2287.70\n",
      "2020-04-17 06:36:45,132 epoch 67 - iter 120/154 - loss 0.12941387 - samples/sec: 2270.73\n",
      "2020-04-17 06:36:45,432 epoch 67 - iter 135/154 - loss 0.12697651 - samples/sec: 2265.70\n",
      "2020-04-17 06:36:45,731 epoch 67 - iter 150/154 - loss 0.12633685 - samples/sec: 2287.87\n",
      "2020-04-17 06:36:45,873 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:45,874 EPOCH 67 done: loss 0.1252 - lr 0.0003\n",
      "2020-04-17 06:36:46,061 DEV : loss 0.21666494011878967 - score 0.9358\n",
      "2020-04-17 06:36:46,069 BAD EPOCHS (no improvement): 5\n",
      "2020-04-17 06:36:46,070 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:46,293 epoch 68 - iter 15/154 - loss 0.11785800 - samples/sec: 2167.28\n",
      "2020-04-17 06:36:46,597 epoch 68 - iter 30/154 - loss 0.11324627 - samples/sec: 2228.45\n",
      "2020-04-17 06:36:46,893 epoch 68 - iter 45/154 - loss 0.11223295 - samples/sec: 2316.51\n",
      "2020-04-17 06:36:47,186 epoch 68 - iter 60/154 - loss 0.11535178 - samples/sec: 2316.13\n",
      "2020-04-17 06:36:47,480 epoch 68 - iter 75/154 - loss 0.11305777 - samples/sec: 2302.87\n",
      "2020-04-17 06:36:47,771 epoch 68 - iter 90/154 - loss 0.11977644 - samples/sec: 2331.22\n",
      "2020-04-17 06:36:48,086 epoch 68 - iter 105/154 - loss 0.11577447 - samples/sec: 2367.55\n",
      "2020-04-17 06:36:48,392 epoch 68 - iter 120/154 - loss 0.11311260 - samples/sec: 2297.56\n",
      "2020-04-17 06:36:48,696 epoch 68 - iter 135/154 - loss 0.11954830 - samples/sec: 2320.28\n",
      "2020-04-17 06:36:49,002 epoch 68 - iter 150/154 - loss 0.11871450 - samples/sec: 2332.76\n",
      "2020-04-17 06:36:49,140 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:49,141 EPOCH 68 done: loss 0.1180 - lr 0.0003\n",
      "2020-04-17 06:36:49,314 DEV : loss 0.2154712826013565 - score 0.9303\n",
      "Epoch    68: reducing learning rate of group 0 to 1.6742e-04.\n",
      "2020-04-17 06:36:49,322 BAD EPOCHS (no improvement): 6\n",
      "2020-04-17 06:36:49,323 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:49,542 epoch 69 - iter 15/154 - loss 0.11019140 - samples/sec: 2206.80\n",
      "2020-04-17 06:36:49,833 epoch 69 - iter 30/154 - loss 0.12264931 - samples/sec: 2335.27\n",
      "2020-04-17 06:36:50,130 epoch 69 - iter 45/154 - loss 0.11475964 - samples/sec: 2272.25\n",
      "2020-04-17 06:36:50,427 epoch 69 - iter 60/154 - loss 0.11878188 - samples/sec: 2274.75\n",
      "2020-04-17 06:36:50,734 epoch 69 - iter 75/154 - loss 0.11886708 - samples/sec: 2283.21\n",
      "2020-04-17 06:36:51,028 epoch 69 - iter 90/154 - loss 0.11649243 - samples/sec: 2292.77\n",
      "2020-04-17 06:36:51,321 epoch 69 - iter 105/154 - loss 0.11923045 - samples/sec: 2306.99\n",
      "2020-04-17 06:36:51,614 epoch 69 - iter 120/154 - loss 0.12497597 - samples/sec: 2311.45\n",
      "2020-04-17 06:36:51,905 epoch 69 - iter 135/154 - loss 0.12853951 - samples/sec: 2343.13\n",
      "2020-04-17 06:36:52,200 epoch 69 - iter 150/154 - loss 0.12788818 - samples/sec: 2294.96\n",
      "2020-04-17 06:36:52,337 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:52,338 EPOCH 69 done: loss 0.1275 - lr 0.0002\n",
      "2020-04-17 06:36:52,514 DEV : loss 0.2156764566898346 - score 0.9339\n",
      "2020-04-17 06:36:52,522 BAD EPOCHS (no improvement): 1\n",
      "2020-04-17 06:36:52,522 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:52,748 epoch 70 - iter 15/154 - loss 0.12756639 - samples/sec: 2148.09\n",
      "2020-04-17 06:36:53,057 epoch 70 - iter 30/154 - loss 0.13349854 - samples/sec: 2299.31\n",
      "2020-04-17 06:36:53,351 epoch 70 - iter 45/154 - loss 0.12909590 - samples/sec: 2329.39\n",
      "2020-04-17 06:36:53,646 epoch 70 - iter 60/154 - loss 0.12668110 - samples/sec: 2307.64\n",
      "2020-04-17 06:36:53,939 epoch 70 - iter 75/154 - loss 0.12169310 - samples/sec: 2328.97\n",
      "2020-04-17 06:36:54,232 epoch 70 - iter 90/154 - loss 0.11866545 - samples/sec: 2321.84\n",
      "2020-04-17 06:36:54,522 epoch 70 - iter 105/154 - loss 0.11732662 - samples/sec: 2345.16\n",
      "2020-04-17 06:36:54,818 epoch 70 - iter 120/154 - loss 0.11824584 - samples/sec: 2290.65\n",
      "2020-04-17 06:36:55,115 epoch 70 - iter 135/154 - loss 0.11710364 - samples/sec: 2285.57\n",
      "2020-04-17 06:36:55,416 epoch 70 - iter 150/154 - loss 0.11835932 - samples/sec: 2260.65\n",
      "2020-04-17 06:36:55,558 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:55,558 EPOCH 70 done: loss 0.1198 - lr 0.0002\n",
      "2020-04-17 06:36:55,742 DEV : loss 0.2161484807729721 - score 0.9376\n",
      "2020-04-17 06:36:55,750 BAD EPOCHS (no improvement): 2\n",
      "2020-04-17 06:36:55,751 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:55,967 epoch 71 - iter 15/154 - loss 0.10062827 - samples/sec: 2242.72\n",
      "2020-04-17 06:36:56,265 epoch 71 - iter 30/154 - loss 0.12667172 - samples/sec: 2264.09\n",
      "2020-04-17 06:36:56,569 epoch 71 - iter 45/154 - loss 0.12373768 - samples/sec: 2223.84\n",
      "2020-04-17 06:36:56,872 epoch 71 - iter 60/154 - loss 0.11496130 - samples/sec: 2210.44\n",
      "2020-04-17 06:36:57,175 epoch 71 - iter 75/154 - loss 0.11752090 - samples/sec: 2215.66\n",
      "2020-04-17 06:36:57,479 epoch 71 - iter 90/154 - loss 0.11770243 - samples/sec: 2204.69\n",
      "2020-04-17 06:36:57,783 epoch 71 - iter 105/154 - loss 0.11412023 - samples/sec: 2217.33\n",
      "2020-04-17 06:36:58,270 epoch 71 - iter 120/154 - loss 0.11346272 - samples/sec: 1292.64\n",
      "2020-04-17 06:36:58,687 epoch 71 - iter 135/154 - loss 0.11773768 - samples/sec: 1455.68\n",
      "2020-04-17 06:36:58,986 epoch 71 - iter 150/154 - loss 0.12240503 - samples/sec: 2281.62\n",
      "2020-04-17 06:36:59,124 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:59,124 EPOCH 71 done: loss 0.1218 - lr 0.0002\n",
      "2020-04-17 06:36:59,300 DEV : loss 0.21626755595207214 - score 0.9376\n",
      "2020-04-17 06:36:59,309 BAD EPOCHS (no improvement): 3\n",
      "2020-04-17 06:36:59,309 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:36:59,539 epoch 72 - iter 15/154 - loss 0.12495731 - samples/sec: 2102.18\n",
      "2020-04-17 06:36:59,844 epoch 72 - iter 30/154 - loss 0.13126618 - samples/sec: 2212.17\n",
      "2020-04-17 06:37:00,149 epoch 72 - iter 45/154 - loss 0.12361176 - samples/sec: 2186.80\n",
      "2020-04-17 06:37:00,510 epoch 72 - iter 60/154 - loss 0.12490752 - samples/sec: 1790.03\n",
      "2020-04-17 06:37:00,918 epoch 72 - iter 75/154 - loss 0.13288998 - samples/sec: 1541.88\n",
      "2020-04-17 06:37:01,221 epoch 72 - iter 90/154 - loss 0.13035285 - samples/sec: 2289.96\n",
      "2020-04-17 06:37:01,526 epoch 72 - iter 105/154 - loss 0.12961072 - samples/sec: 2256.14\n",
      "2020-04-17 06:37:01,825 epoch 72 - iter 120/154 - loss 0.12986704 - samples/sec: 2317.32\n",
      "2020-04-17 06:37:02,286 epoch 72 - iter 135/154 - loss 0.12654795 - samples/sec: 1309.64\n",
      "2020-04-17 06:37:02,596 epoch 72 - iter 150/154 - loss 0.12901131 - samples/sec: 2239.81\n",
      "2020-04-17 06:37:02,741 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:37:02,742 EPOCH 72 done: loss 0.1271 - lr 0.0002\n",
      "2020-04-17 06:37:02,923 DEV : loss 0.21596916019916534 - score 0.9358\n",
      "2020-04-17 06:37:02,931 BAD EPOCHS (no improvement): 4\n",
      "2020-04-17 06:37:02,932 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:37:03,154 epoch 73 - iter 15/154 - loss 0.14717487 - samples/sec: 2175.79\n",
      "2020-04-17 06:37:03,458 epoch 73 - iter 30/154 - loss 0.14371620 - samples/sec: 2273.28\n",
      "2020-04-17 06:37:03,761 epoch 73 - iter 45/154 - loss 0.12739363 - samples/sec: 2277.50\n",
      "2020-04-17 06:37:04,065 epoch 73 - iter 60/154 - loss 0.12413303 - samples/sec: 2280.47\n",
      "2020-04-17 06:37:04,361 epoch 73 - iter 75/154 - loss 0.12904804 - samples/sec: 2282.71\n",
      "2020-04-17 06:37:04,850 epoch 73 - iter 90/154 - loss 0.12524685 - samples/sec: 1197.44\n",
      "2020-04-17 06:37:05,161 epoch 73 - iter 105/154 - loss 0.12343608 - samples/sec: 2247.91\n",
      "2020-04-17 06:37:05,599 epoch 73 - iter 120/154 - loss 0.12176749 - samples/sec: 1423.27\n",
      "2020-04-17 06:37:05,890 epoch 73 - iter 135/154 - loss 0.12412334 - samples/sec: 2335.68\n",
      "2020-04-17 06:37:06,185 epoch 73 - iter 150/154 - loss 0.12369026 - samples/sec: 2297.54\n",
      "2020-04-17 06:37:06,324 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:37:06,325 EPOCH 73 done: loss 0.1231 - lr 0.0002\n",
      "2020-04-17 06:37:06,502 DEV : loss 0.21588662266731262 - score 0.9358\n",
      "2020-04-17 06:37:06,510 BAD EPOCHS (no improvement): 5\n",
      "2020-04-17 06:37:06,511 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:37:06,734 epoch 74 - iter 15/154 - loss 0.09716597 - samples/sec: 2161.49\n",
      "2020-04-17 06:37:07,222 epoch 74 - iter 30/154 - loss 0.10911962 - samples/sec: 1199.03\n",
      "2020-04-17 06:37:07,522 epoch 74 - iter 45/154 - loss 0.11776091 - samples/sec: 2273.27\n",
      "2020-04-17 06:37:07,822 epoch 74 - iter 60/154 - loss 0.11873318 - samples/sec: 2276.82\n",
      "2020-04-17 06:37:08,124 epoch 74 - iter 75/154 - loss 0.11681094 - samples/sec: 2253.20\n",
      "2020-04-17 06:37:08,425 epoch 74 - iter 90/154 - loss 0.11584602 - samples/sec: 2259.32\n",
      "2020-04-17 06:37:08,722 epoch 74 - iter 105/154 - loss 0.11214628 - samples/sec: 2308.92\n",
      "2020-04-17 06:37:09,019 epoch 74 - iter 120/154 - loss 0.11441896 - samples/sec: 2321.82\n",
      "2020-04-17 06:37:09,316 epoch 74 - iter 135/154 - loss 0.11526282 - samples/sec: 2349.42\n",
      "2020-04-17 06:37:09,623 epoch 74 - iter 150/154 - loss 0.11559517 - samples/sec: 2300.80\n",
      "2020-04-17 06:37:09,767 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:37:09,768 EPOCH 74 done: loss 0.1158 - lr 0.0002\n",
      "2020-04-17 06:37:09,946 DEV : loss 0.21603669226169586 - score 0.9339\n",
      "Epoch    74: reducing learning rate of group 0 to 8.3712e-05.\n",
      "2020-04-17 06:37:09,954 BAD EPOCHS (no improvement): 6\n",
      "2020-04-17 06:37:09,955 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:37:09,955 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:37:09,956 learning rate too small - quitting training!\n",
      "2020-04-17 06:37:09,956 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:37:10,465 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-17 06:37:10,466 Testing using best model ...\n",
      "2020-04-17 06:37:10,467 loading file Path/to/model/output/directory/best-model.pt\n",
      "2020-04-17 06:37:11,250 0.966\t0.966\t0.966\n",
      "2020-04-17 06:37:11,250 \n",
      "MICRO_AVG: acc 0.9342 - f1-score 0.966\n",
      "MACRO_AVG: acc 0.9447 - f1-score 0.9709500000000001\n",
      "ABBR       tp: 9 - fp: 0 - fn: 0 - tn: 491 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
      "DESC       tp: 135 - fp: 5 - fn: 3 - tn: 357 - precision: 0.9643 - recall: 0.9783 - accuracy: 0.9441 - f1-score: 0.9712\n",
      "ENTY       tp: 84 - fp: 5 - fn: 10 - tn: 401 - precision: 0.9438 - recall: 0.8936 - accuracy: 0.8485 - f1-score: 0.9180\n",
      "HUM        tp: 63 - fp: 1 - fn: 2 - tn: 434 - precision: 0.9844 - recall: 0.9692 - accuracy: 0.9545 - f1-score: 0.9767\n",
      "LOC        tp: 80 - fp: 2 - fn: 1 - tn: 417 - precision: 0.9756 - recall: 0.9877 - accuracy: 0.9639 - f1-score: 0.9816\n",
      "NUM        tp: 112 - fp: 4 - fn: 1 - tn: 383 - precision: 0.9655 - recall: 0.9912 - accuracy: 0.9573 - f1-score: 0.9782\n",
      "2020-04-17 06:37:11,251 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sc_train_configs = {\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"mini_batch_size\": 32,\n",
    "        \"anneal_factor\": 0.5,\n",
    "        \"patience\": 5,\n",
    "        \"max_epochs\": 150,\n",
    "        \"plot_weights\": False,\n",
    "        \"batch_growth_annealing\": False,\n",
    "}\n",
    "sc_trainer.train(**sc_train_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-17 06:37:46,875 loading file Path/to/model/output/directory/final-model.pt\n",
      "Label output:\n",
      "\n",
      "[LOC (0.9990556836128235)]\n"
     ]
    }
   ],
   "source": [
    "from adaptnlp import EasySequenceClassifier\n",
    "# Set example text and instantiate tagger instance\n",
    "example_text = '''Where was the Queen's wedding held? '''\n",
    "\n",
    "classifier = EasySequenceClassifier()\n",
    "\n",
    "sentences = classifier.tag_text(example_text, model_name_or_path=OUTPUT_DIR + \"/final-model.pt\")\n",
    "print(\"Label output:\\n\")\n",
    "for sentence in sentences:\n",
    "    print(sentence.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sequence Classifier on Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TREC_6() # Or path to directory of train.csv, test.csv, dev.csv files at \"Path/to/data/directory\" \n",
    "OUTPUT_DIR = \"Path/to/model/output/directory\"\n",
    "FINETUNED_MODEL_DIR = \"Path/to/finetuned/model/directory\"\n",
    "doc_embeddings = EasyDocumentEmbeddings(FINETUNED_MODEL_DIR, methods = [\"rnn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_configs = {\n",
    "              \"corpus\": corpus,\n",
    "              \"encoder\": doc_embeddings,\n",
    "              \"column_name_map\": {0: \"text\", 1: \"label\"},\n",
    "              \"corpus_in_memory\": True,\n",
    "              \"predictive_head\": \"flair\",\n",
    "             }\n",
    "sc_trainer = SequenceClassifierTrainer(**sc_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_lr_configs = {\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \"start_learning_rate\": 1e-8,\n",
    "        \"end_learning_rate\": 10,\n",
    "        \"iterations\": 100,\n",
    "        \"mini_batch_size\": 32,\n",
    "        \"stop_early\": True,\n",
    "        \"smoothing_factor\": 0.8,\n",
    "        \"plot_learning_rate\": True,\n",
    "}\n",
    "learning_rate = sc_trainer.find_learning_rate(**sc_lr_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train_configs = {\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"mini_batch_size\": 32,\n",
    "        \"anneal_factor\": 0.5,\n",
    "        \"patience\": 5,\n",
    "        \"max_epochs\": 150,\n",
    "        \"plot_weights\": False,\n",
    "        \"batch_growth_annealing\": False,\n",
    "}\n",
    "sc_trainer.train(**sc_train_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
